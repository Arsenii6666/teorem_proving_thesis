{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_paper_id=\"87875a07976c26f82705de1fc70041169e5d652b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from collections import deque\n",
    "import os\n",
    "import zipfile\n",
    "import pdfplumber\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations_from_semantic_scholar(paper_id):\n",
    "    url = f\"https://api.semanticscholar.org/v1/paper/{paper_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        citations = data.get(\"citations\", [])\n",
    "        return citations\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'arxivId': '2412.16075',\n",
       "  'authors': [{'authorId': '2336860219', 'name': 'Kaiyu Yang'},\n",
       "   {'authorId': '2113249490', 'name': 'Gabriel Poesia'},\n",
       "   {'authorId': '2337844852', 'name': 'Jingxuan He'},\n",
       "   {'authorId': '2336828803', 'name': 'Wenda Li'},\n",
       "   {'authorId': '2336739192', 'name': 'Kristin Lauter'},\n",
       "   {'authorId': '2248225759', 'name': 'Swarat Chaudhuri'},\n",
       "   {'authorId': '2336822895', 'name': 'Dawn Song'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '7899f3ec633080ac9d9b6458f1e1c35e86e6ec5c',\n",
       "  'title': 'Formal Mathematical Reasoning: A New Frontier in AI',\n",
       "  'url': 'https://www.semanticscholar.org/paper/7899f3ec633080ac9d9b6458f1e1c35e86e6ec5c',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2412.14141',\n",
       "  'authors': [{'authorId': '2335869617', 'name': 'Tianyang Gu'},\n",
       "   {'authorId': '2336059081', 'name': 'Jingjin Wang'},\n",
       "   {'authorId': '2336026962', 'name': 'Zhihao Zhang'},\n",
       "   {'authorId': '2336144054', 'name': 'HaoHong Li'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '15c6424bec1d954985771361cabc5f1fc8db558c',\n",
       "  'title': 'LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research',\n",
       "  'url': 'https://www.semanticscholar.org/paper/15c6424bec1d954985771361cabc5f1fc8db558c',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2412.11427',\n",
       "  'authors': [{'authorId': '2262444977', 'name': 'Chandan K. Reddy'},\n",
       "   {'authorId': '2037848556', 'name': 'Parshin Shojaee'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '8a816b4d4ee63804615dba39269948fda63b1c21',\n",
       "  'title': 'Towards Scientific Discovery with Generative AI: Progress, Opportunities, and Challenges',\n",
       "  'url': 'https://www.semanticscholar.org/paper/8a816b4d4ee63804615dba39269948fda63b1c21',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2411.17501',\n",
       "  'authors': [{'authorId': '2309175570', 'name': 'Benedikt Stroebl'},\n",
       "   {'authorId': '39893263', 'name': 'Sayash Kapoor'},\n",
       "   {'authorId': '2064013115', 'name': 'Arvind Narayanan'}],\n",
       "  'doi': '10.48550/arXiv.2411.17501',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '5bb98b72874e2dc80a8937558968c87e88269e79',\n",
       "  'title': 'Inference Scaling fLaws: The Limits of LLM Resampling with Imperfect Verifiers',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5bb98b72874e2dc80a8937558968c87e88269e79',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2308228422', 'name': 'M. Joudakizadeh'},\n",
       "   {'authorId': '2311582858', 'name': 'A.P. Beltiukov'}],\n",
       "  'doi': '10.35634/2226-3594-2024-64-02',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '750578781f02d0a0c8479cdc676b262472eea1cf',\n",
       "  'title': 'Adaptive human–machine theorem proving system',\n",
       "  'url': 'https://www.semanticscholar.org/paper/750578781f02d0a0c8479cdc676b262472eea1cf',\n",
       "  'venue': 'Izvestiya Instituta Matematiki i Informatiki Udmurtskogo Gosudarstvennogo Universiteta',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2411.01829',\n",
       "  'authors': [{'authorId': '2057563900', 'name': 'Kefan Dong'},\n",
       "   {'authorId': '103351641', 'name': 'Arvind V. Mahankali'},\n",
       "   {'authorId': '2329165431', 'name': 'Tengyu Ma'}],\n",
       "  'doi': '10.48550/arXiv.2411.01829',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'cd716e9a5edf6394f12aad016da864646af6d676',\n",
       "  'title': 'Formal Theorem Proving by Rewarding LLMs to Decompose Proofs Hierarchically',\n",
       "  'url': 'https://www.semanticscholar.org/paper/cd716e9a5edf6394f12aad016da864646af6d676',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2411.00863',\n",
       "  'authors': [{'authorId': '2295988926', 'name': 'Chenyang An'},\n",
       "   {'authorId': '40203626', 'name': 'Shima Imani'},\n",
       "   {'authorId': '2329096390', 'name': 'Feng Yao'},\n",
       "   {'authorId': '2113540861', 'name': 'Chengyu Dong'},\n",
       "   {'authorId': '2329097767', 'name': 'Ali Abbasi'},\n",
       "   {'authorId': '2278440111', 'name': 'Harsh Shrivastava'},\n",
       "   {'authorId': '2329093199', 'name': 'Samuel Buss'},\n",
       "   {'authorId': '2297773933', 'name': 'Jingbo Shang'},\n",
       "   {'authorId': '2282023311', 'name': 'Gayathri Mahalingam'},\n",
       "   {'authorId': '2329377941', 'name': 'Pramod Sharma'},\n",
       "   {'authorId': '2237424849', 'name': 'Maurice Diesendruck'}],\n",
       "  'doi': '10.48550/arXiv.2411.00863',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '9af2b5e1406228636304e2ce1ef8153d5988aecc',\n",
       "  'title': 'Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/9af2b5e1406228636304e2ce1ef8153d5988aecc',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.18494',\n",
       "  'authors': [{'authorId': '2223115672', 'name': 'Martin Mirchev'},\n",
       "   {'authorId': '32051796', 'name': 'Andreea Costea'},\n",
       "   {'authorId': '2327392815', 'name': 'Abhishek Kr Singh'},\n",
       "   {'authorId': '97501532', 'name': 'Abhik Roychoudhury'}],\n",
       "  'doi': '10.48550/arXiv.2410.18494',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '0afdd882c42b1c86602957156b1c74629e385b2d',\n",
       "  'title': 'Assured Automatic Programming via Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/0afdd882c42b1c86602957156b1c74629e385b2d',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.18194',\n",
       "  'authors': [{'authorId': '2327335275', 'name': 'Elyas Obbad'},\n",
       "   {'authorId': '2297852216', 'name': 'Iddah Mlauzi'},\n",
       "   {'authorId': '2239107390', 'name': 'Brando Miranda'},\n",
       "   {'authorId': '1749176844', 'name': 'Rylan Schaeffer'},\n",
       "   {'authorId': '2327335061', 'name': 'Kamal Obbad'},\n",
       "   {'authorId': '2296770804', 'name': 'Suhana Bedi'},\n",
       "   {'authorId': '143812875', 'name': 'Oluwasanmi Koyejo'}],\n",
       "  'doi': '10.48550/arXiv.2410.18194',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '77b4fd31f5090e76f72b29d842737476a46a233f',\n",
       "  'title': 'ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment',\n",
       "  'url': 'https://www.semanticscholar.org/paper/77b4fd31f5090e76f72b29d842737476a46a233f',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.16973',\n",
       "  'authors': [{'authorId': '2327053478', 'name': 'Antoine Gorceix'},\n",
       "   {'authorId': '2327053489', 'name': 'Bastien Le Chenadec'},\n",
       "   {'authorId': '2212957124', 'name': 'Ahmad Rammal'},\n",
       "   {'authorId': '38921168', 'name': 'N. Vadori'},\n",
       "   {'authorId': '2327051831', 'name': 'Manuela Veloso'}],\n",
       "  'doi': None,\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '5855568b6979e72ee0817c8d027e0aab88edfdc7',\n",
       "  'title': 'Learning Mathematical Rules with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5855568b6979e72ee0817c8d027e0aab88edfdc7',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.17161',\n",
       "  'authors': [{'authorId': '2137508907', 'name': 'I. Isik'},\n",
       "   {'authorId': '1939006', 'name': 'R. G. Cinbis'},\n",
       "   {'authorId': '2224351', 'name': 'Ebru Aydin Gol'}],\n",
       "  'doi': '10.48550/arXiv.2410.17161',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '661d446028bf754649be951f28b8ee40a15e3a48',\n",
       "  'title': 'Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence',\n",
       "  'url': 'https://www.semanticscholar.org/paper/661d446028bf754649be951f28b8ee40a15e3a48',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.15748',\n",
       "  'authors': [{'authorId': '2327375420', 'name': 'Shaonan Wu'},\n",
       "   {'authorId': '2274063415', 'name': 'Shuai Lu'},\n",
       "   {'authorId': '2254121650', 'name': 'Yeyun Gong'},\n",
       "   {'authorId': '2273685555', 'name': 'Nan Duan'},\n",
       "   {'authorId': '2326993699', 'name': 'Ping Wei'}],\n",
       "  'doi': '10.48550/arXiv.2410.15748',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'f13fd43670c1fbec996eef685cf3030784779f16',\n",
       "  'title': 'Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f13fd43670c1fbec996eef685cf3030784779f16',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.15756',\n",
       "  'authors': [{'authorId': '2255884021', 'name': 'Tianyu Chen'},\n",
       "   {'authorId': '2322658447', 'name': 'Shuai Lu'},\n",
       "   {'authorId': '2322658450', 'name': 'Shan Lu'},\n",
       "   {'authorId': '2254121650', 'name': 'Yeyun Gong'},\n",
       "   {'authorId': '2322390266', 'name': 'Chenyuan Yang'},\n",
       "   {'authorId': '2322285555', 'name': 'Xuheng Li'},\n",
       "   {'authorId': '36457920', 'name': 'Md Rakib Hossain Misu'},\n",
       "   {'authorId': '2327005436', 'name': 'Hao Yu'},\n",
       "   {'authorId': '2273685555', 'name': 'Nan Duan'},\n",
       "   {'authorId': '2331750892', 'name': 'Peng Cheng'},\n",
       "   {'authorId': '2322349602', 'name': 'Fan Yang'},\n",
       "   {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'},\n",
       "   {'authorId': '2326991819', 'name': 'Tao Xie'},\n",
       "   {'authorId': '2143359114', 'name': 'Lidong Zhou'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '528ebaaace61d47559447c04a800a8a338fb4040',\n",
       "  'title': 'Automated Proof Generation for Rust Code via Self-Evolution',\n",
       "  'url': 'https://www.semanticscholar.org/paper/528ebaaace61d47559447c04a800a8a338fb4040',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.16429',\n",
       "  'authors': [{'authorId': '2221102713', 'name': 'Leni Aniva'},\n",
       "   {'authorId': '2262463672', 'name': 'Chuyue Sun'},\n",
       "   {'authorId': '2239107390', 'name': 'Brando Miranda'},\n",
       "   {'authorId': '2262214357', 'name': 'Clark W. Barrett'},\n",
       "   {'authorId': '143812875', 'name': 'Oluwasanmi Koyejo'}],\n",
       "  'doi': '10.48550/arXiv.2410.16429',\n",
       "  'intent': ['result', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '325ed3c67d014a68e605053e656174c43ceb87cd',\n",
       "  'title': 'Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4',\n",
       "  'url': 'https://www.semanticscholar.org/paper/325ed3c67d014a68e605053e656174c43ceb87cd',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.15700',\n",
       "  'authors': [{'authorId': '2283840256', 'name': 'Zijian Wu'},\n",
       "   {'authorId': '2326995898', 'name': 'Suozhi Huang'},\n",
       "   {'authorId': '2157944555', 'name': 'Zhejian Zhou'},\n",
       "   {'authorId': '2283772353', 'name': 'Huaiyuan Ying'},\n",
       "   {'authorId': '2283823680', 'name': 'Jiayu Wang'},\n",
       "   {'authorId': '2261095726', 'name': 'Dahua Lin'},\n",
       "   {'authorId': '2275790072', 'name': 'Kai Chen'}],\n",
       "  'doi': '10.48550/arXiv.2410.15700',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '5b3cd003ae273b5ae9c29259e1db1b67a97cfd4e',\n",
       "  'title': 'InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5b3cd003ae273b5ae9c29259e1db1b67a97cfd4e',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.14835',\n",
       "  'authors': [{'authorId': '73732832', 'name': 'Prasita Mukherjee'},\n",
       "   {'authorId': '2322445193', 'name': 'Benjamin Delaware'}],\n",
       "  'doi': '10.48550/arXiv.2410.14835',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '19cb3d9023d48529aa2e1ab5576f94818e98848b',\n",
       "  'title': 'Towards Automated Verification of LLM-Synthesized C Programs',\n",
       "  'url': 'https://www.semanticscholar.org/paper/19cb3d9023d48529aa2e1ab5576f94818e98848b',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.13224',\n",
       "  'authors': [{'authorId': '2326297760', 'name': 'Matthew Ho'},\n",
       "   {'authorId': '2307016125', 'name': 'Vincent Zhu'},\n",
       "   {'authorId': '2109383770', 'name': 'Xiaoyin Chen'},\n",
       "   {'authorId': '1383135665', 'name': 'Moksh Jain'},\n",
       "   {'authorId': '2067020770', 'name': 'Nikolay Malkin'},\n",
       "   {'authorId': '2319131169', 'name': 'Edwin Zhang'}],\n",
       "  'doi': '10.48550/arXiv.2410.13224',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'dbc85428a085de4e99ef42878d2febbdcdd5c280',\n",
       "  'title': 'Proof Flow: Preliminary Study on Generative Flow Network Language Model Tuning for Formal Reasoning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/dbc85428a085de4e99ef42878d2febbdcdd5c280',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.13185',\n",
       "  'authors': [{'authorId': '2326448748', 'name': 'Long Li'},\n",
       "   {'authorId': '2313881740', 'name': 'Weiwen Xu'},\n",
       "   {'authorId': '5765645', 'name': 'Jiayan Guo'},\n",
       "   {'authorId': '2091437375', 'name': 'Ruochen Zhao'},\n",
       "   {'authorId': '2326341023', 'name': 'Xinxuan Li'},\n",
       "   {'authorId': '2258794044', 'name': 'Yuqian Yuan'},\n",
       "   {'authorId': '2326705179', 'name': 'Boqiang Zhang'},\n",
       "   {'authorId': '2326473480', 'name': 'Yuming Jiang'},\n",
       "   {'authorId': '112862525', 'name': 'Yifei Xin'},\n",
       "   {'authorId': '2326299612', 'name': 'Ronghao Dang'},\n",
       "   {'authorId': '2303980061', 'name': 'Deli Zhao'},\n",
       "   {'authorId': '2326302367', 'name': 'Yu Rong'},\n",
       "   {'authorId': '2326302705', 'name': 'Tian Feng'},\n",
       "   {'authorId': '2211459675', 'name': 'Li Bing'}],\n",
       "  'doi': '10.48550/arXiv.2410.13185',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '63aa9598da11da04d044ecf7211b2055b7a1775c',\n",
       "  'title': 'Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents',\n",
       "  'url': 'https://www.semanticscholar.org/paper/63aa9598da11da04d044ecf7211b2055b7a1775c',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.13413',\n",
       "  'authors': [{'authorId': '2296944723', 'name': 'Chengyu Du'},\n",
       "   {'authorId': '2326471984', 'name': 'Jinyi Han'},\n",
       "   {'authorId': '2326296953', 'name': 'Yizhou Ying'},\n",
       "   {'authorId': '2298944454', 'name': 'Aili Chen'},\n",
       "   {'authorId': '2152880833', 'name': 'Qi He'},\n",
       "   {'authorId': '2296746816', 'name': 'Haokun Zhao'},\n",
       "   {'authorId': '2309175505', 'name': 'Sirui Xia'},\n",
       "   {'authorId': '2292575776', 'name': 'Haoran Guo'},\n",
       "   {'authorId': '3366523', 'name': 'Jiaqing Liang'},\n",
       "   {'authorId': '2297333418', 'name': 'Zulong Chen'},\n",
       "   {'authorId': '2145728192', 'name': 'Liangyue Li'},\n",
       "   {'authorId': '2316676568', 'name': 'Yanghua Xiao'}],\n",
       "  'doi': '10.48550/arXiv.2410.13413',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '118a2176c4b93c150026e71bf9708f45ae980011',\n",
       "  'title': 'Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/118a2176c4b93c150026e71bf9708f45ae980011',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.23299',\n",
       "  'authors': [{'authorId': '2304031193', 'name': 'Minwoo Kang'},\n",
       "   {'authorId': '2264029479', 'name': 'Mingjie Liu'},\n",
       "   {'authorId': '30960103', 'name': 'Ghaith Bany Hamad'},\n",
       "   {'authorId': '2286631526', 'name': 'Syed Suhaib'},\n",
       "   {'authorId': '2268825069', 'name': 'Haoxing Ren'}],\n",
       "  'doi': '10.48550/arXiv.2410.23299',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '995ad0c0c9811ac3b3c5ab460764fe4b84328f9a',\n",
       "  'title': 'FVEval: Understanding Language Model Capabilities in Formal Verification of Digital Hardware',\n",
       "  'url': 'https://www.semanticscholar.org/paper/995ad0c0c9811ac3b3c5ab460764fe4b84328f9a',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.11133',\n",
       "  'authors': [{'authorId': '2290074695', 'name': 'Sean Lamont'},\n",
       "   {'authorId': '2290070197', 'name': 'Christian Walder'},\n",
       "   {'authorId': '2290077153', 'name': 'Amir Dezfouli'},\n",
       "   {'authorId': '2290075652', 'name': 'Paul Montague'},\n",
       "   {'authorId': '2290070273', 'name': 'Michael Norrish'}],\n",
       "  'doi': '10.48550/arXiv.2410.11133',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '473ec8d855adc1dbbfbb562d0a7c425a45b28e06',\n",
       "  'title': '3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes',\n",
       "  'url': 'https://www.semanticscholar.org/paper/473ec8d855adc1dbbfbb562d0a7c425a45b28e06',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.10135',\n",
       "  'authors': [{'authorId': '2302633318', 'name': 'Jianqiao Lu'},\n",
       "   {'authorId': '2303955786', 'name': 'Yingjia Wan'},\n",
       "   {'authorId': '2303470248', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2175277130', 'name': 'Jing Xiong'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2681038', 'name': 'Zhijiang Guo'}],\n",
       "  'doi': '10.48550/arXiv.2410.10135',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '5b5be0a0965c6f3314489b38c41c349f07fb95a1',\n",
       "  'title': 'FormalAlign: Automated Alignment Evaluation for Autoformalization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5b5be0a0965c6f3314489b38c41c349f07fb95a1',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.09412',\n",
       "  'authors': [{'authorId': '2325902806', 'name': 'Youquan Li'},\n",
       "   {'authorId': '2310811681', 'name': 'Miao Zheng'},\n",
       "   {'authorId': '2310445518', 'name': 'Fan Yang'},\n",
       "   {'authorId': '2242124536', 'name': 'Guosheng Dong'},\n",
       "   {'authorId': '2260817839', 'name': 'Bin Cui'},\n",
       "   {'authorId': '2299165327', 'name': 'Weipeng Chen'},\n",
       "   {'authorId': '2183768304', 'name': 'Zenan Zhou'},\n",
       "   {'authorId': '2316516244', 'name': 'Wentao Zhang'}],\n",
       "  'doi': '10.48550/arXiv.2410.09412',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f9c1a7de0e21a2c650b8d42a32d003047b4561c4',\n",
       "  'title': \"FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs' Responsiveness to Human Feedback\",\n",
       "  'url': 'https://www.semanticscholar.org/paper/f9c1a7de0e21a2c650b8d42a32d003047b4561c4',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.08437',\n",
       "  'authors': [{'authorId': '72254820', 'name': 'Rushang Karia'},\n",
       "   {'authorId': '2293614312', 'name': 'Daniel Bramblett'},\n",
       "   {'authorId': '1387180660', 'name': 'D. Dobhal'},\n",
       "   {'authorId': '2283933883', 'name': 'Siddharth Srivastava'}],\n",
       "  'doi': '10.48550/arXiv.2410.08437',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'e4a4a98cf3ce47937c406918f43f35f494273498',\n",
       "  'title': '∀uto∃∨∧L: Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e4a4a98cf3ce47937c406918f43f35f494273498',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.07961',\n",
       "  'authors': [{'authorId': '2325211239', 'name': 'Rui Yang'},\n",
       "   {'authorId': '2325261299', 'name': 'Yuntian Gu'},\n",
       "   {'authorId': '2325195735', 'name': 'Ziruo Wang'},\n",
       "   {'authorId': '2325728026', 'name': 'Yitao Liang'},\n",
       "   {'authorId': '2268725640', 'name': 'Tongyang Li'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '65ee567071d4353d350a8dbd76e8b9f2d3f2c154',\n",
       "  'title': 'QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design',\n",
       "  'url': 'https://www.semanticscholar.org/paper/65ee567071d4353d350a8dbd76e8b9f2d3f2c154',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.06209',\n",
       "  'authors': [{'authorId': '2325095741', 'name': 'Adarsh Kumarappan'},\n",
       "   {'authorId': '2324979027', 'name': 'Mo Tiwari'},\n",
       "   {'authorId': '2297671110', 'name': 'Peiyang Song'},\n",
       "   {'authorId': '2292196316', 'name': 'Robert Joseph George'},\n",
       "   {'authorId': '2325856395', 'name': 'Chaowei Xiao'},\n",
       "   {'authorId': '2257161858', 'name': 'A. Anandkumar'}],\n",
       "  'doi': '10.48550/arXiv.2410.06209',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'c3b60318038abdee2df8df85ba06475b824d1fd9',\n",
       "  'title': 'LeanAgent: Lifelong Learning for Formal Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/c3b60318038abdee2df8df85ba06475b824d1fd9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.04753',\n",
       "  'authors': [{'authorId': '2324784907', 'name': 'Riyaz Ahuja'},\n",
       "   {'authorId': '2312131605', 'name': 'Jeremy Avigad'},\n",
       "   {'authorId': '2259188971', 'name': 'Prasad Tetali'},\n",
       "   {'authorId': '2307087901', 'name': 'Sean J. Welleck'}],\n",
       "  'doi': '10.48550/arXiv.2410.04753',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4bddc593589b88fdbc7fbafa0b476064d3c7eda3',\n",
       "  'title': 'ImProver: Agent-Based Automated Proof Optimization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/4bddc593589b88fdbc7fbafa0b476064d3c7eda3',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2410.04194',\n",
       "  'authors': [{'authorId': '2109006173', 'name': 'Lan Zhang'},\n",
       "   {'authorId': '2282137151', 'name': 'Xin Quan'},\n",
       "   {'authorId': '2324783803', 'name': 'Andre Freitas'}],\n",
       "  'doi': '10.48550/arXiv.2410.04194',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'c2be68bb31fcfbb9bbcab951cebf8c9a1b096ece',\n",
       "  'title': 'Consistent Autoformalization for Constructing Mathematical Libraries',\n",
       "  'url': 'https://www.semanticscholar.org/paper/c2be68bb31fcfbb9bbcab951cebf8c9a1b096ece',\n",
       "  'venue': 'EMNLP',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2278423357', 'name': 'Andrés Márquez'},\n",
       "   {'authorId': '2324806650', 'name': 'Ted Fujimoto'},\n",
       "   {'authorId': '92964915', 'name': 'T. Stavenger'}],\n",
       "  'doi': '10.2172/2455011',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '1577dc7c0caea1148ffd5f339e356e4aee9c7017',\n",
       "  'title': 'Assurance of Reasoning Enabled Systems (ARES)',\n",
       "  'url': 'https://www.semanticscholar.org/paper/1577dc7c0caea1148ffd5f339e356e4aee9c7017',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2409.14924',\n",
       "  'authors': [{'authorId': '2268432582', 'name': 'Siyun Zhao'},\n",
       "   {'authorId': '2125051198', 'name': 'Yuqing Yang'},\n",
       "   {'authorId': '2294387070', 'name': 'Zilong Wang'},\n",
       "   {'authorId': '2260609693', 'name': 'Zhiyuan He'},\n",
       "   {'authorId': '2180993402', 'name': 'Luna K. Qiu'},\n",
       "   {'authorId': '2259937079', 'name': 'Lili Qiu'}],\n",
       "  'doi': '10.48550/arXiv.2409.14924',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '339d2a56f0e5176b691c358a86891e2923045c8c',\n",
       "  'title': 'Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely',\n",
       "  'url': 'https://www.semanticscholar.org/paper/339d2a56f0e5176b691c358a86891e2923045c8c',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2409.13082',\n",
       "  'authors': [{'authorId': '2322390266', 'name': 'Chenyuan Yang'},\n",
       "   {'authorId': '2322285555', 'name': 'Xuheng Li'},\n",
       "   {'authorId': '36457920', 'name': 'Md Rakib Hossain Misu'},\n",
       "   {'authorId': '2265584324', 'name': 'Jianan Yao'},\n",
       "   {'authorId': '2265609063', 'name': 'Weidong Cui'},\n",
       "   {'authorId': '2254121650', 'name': 'Yeyun Gong'},\n",
       "   {'authorId': '2311498021', 'name': 'Chris Hawblitzel'},\n",
       "   {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'},\n",
       "   {'authorId': '2322097834', 'name': 'Jacob R. Lorch'},\n",
       "   {'authorId': '2322658447', 'name': 'Shuai Lu'},\n",
       "   {'authorId': '2322349602', 'name': 'Fan Yang'},\n",
       "   {'authorId': '2265584402', 'name': 'Ziqiao Zhou'},\n",
       "   {'authorId': '2322658450', 'name': 'Shan Lu'}],\n",
       "  'doi': '10.48550/arXiv.2409.13082',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '749534d09a30a0b69fce63b1e304638791a596df',\n",
       "  'title': 'AutoVerus: Automated Proof Generation for Rust Code',\n",
       "  'url': 'https://www.semanticscholar.org/paper/749534d09a30a0b69fce63b1e304638791a596df',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.11815',\n",
       "  'authors': [{'authorId': '2316559065', 'name': 'Shangyi Geng'},\n",
       "   {'authorId': '2261885338', 'name': 'Wenting Zhao'},\n",
       "   {'authorId': '2312751781', 'name': 'Alexander M. Rush'}],\n",
       "  'doi': '10.48550/arXiv.2408.11815',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a02d446e4c302a084c2da95ef40b6f2a4e098b1b',\n",
       "  'title': 'Great Memory, Shallow Reasoning: Limits of kNN-LMs',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a02d446e4c302a084c2da95ef40b6f2a4e098b1b',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.10205',\n",
       "  'authors': [{'authorId': '2145253202', 'name': 'Ziming Liu'},\n",
       "   {'authorId': '2268495546', 'name': 'Pingchuan Ma'},\n",
       "   {'authorId': '2299114926', 'name': 'Yixuan Wang'},\n",
       "   {'authorId': '2295306221', 'name': 'Wojciech Matusik'},\n",
       "   {'authorId': '2253461463', 'name': 'Max Tegmark'}],\n",
       "  'doi': '10.48550/arXiv.2408.10205',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'd9de0c1c8d21ec9cb8bd430ca98569e08328d882',\n",
       "  'title': 'KAN 2.0: Kolmogorov-Arnold Networks Meet Science',\n",
       "  'url': 'https://www.semanticscholar.org/paper/d9de0c1c8d21ec9cb8bd430ca98569e08328d882',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.09237',\n",
       "  'authors': [{'authorId': '1406432713', 'name': 'Alex Sanchez-Stern'},\n",
       "   {'authorId': '2316428790', 'name': 'Abhishek Varghese'},\n",
       "   {'authorId': '2163391892', 'name': 'Zhanna Kaufman'},\n",
       "   {'authorId': '2280893328', 'name': 'Dylan Zhang'},\n",
       "   {'authorId': '2280334022', 'name': 'Talia Ringer'},\n",
       "   {'authorId': '2316428804', 'name': 'Yuriy Brun'}],\n",
       "  'doi': '10.1109/ICSE55347.2025.00033',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'd04d1db70492c49049f971a9709040a87bf39730',\n",
       "  'title': 'QEDCartographer: Automating Formal Verification Using Reward-Free Reinforcement Learning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/d04d1db70492c49049f971a9709040a87bf39730',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.08152',\n",
       "  'authors': [{'authorId': '2238628841', 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2304140796', 'name': 'Z. Ren'},\n",
       "   {'authorId': '2258088582', 'name': 'Jun-Mei Song'},\n",
       "   {'authorId': '2302778018', 'name': 'Zhihong Shao'},\n",
       "   {'authorId': '2257129965', 'name': 'Wanjia Zhao'},\n",
       "   {'authorId': '2316174862', 'name': 'Haocheng Wang'},\n",
       "   {'authorId': '2156640188', 'name': 'Bo Liu (Benjamin Liu)'},\n",
       "   {'authorId': '2278257096', 'name': 'Liyue Zhang'},\n",
       "   {'authorId': '2307222549', 'name': 'Xuan Lu'},\n",
       "   {'authorId': '2278218583', 'name': 'Qiushi Du'},\n",
       "   {'authorId': '2272467392', 'name': 'W. Gao'},\n",
       "   {'authorId': '2278223869', 'name': 'Qihao Zhu'},\n",
       "   {'authorId': '2278404250', 'name': 'Dejian Yang'},\n",
       "   {'authorId': '1797090', 'name': 'Zhibin Gou'},\n",
       "   {'authorId': '2316170048', 'name': 'Z. F. Wu'},\n",
       "   {'authorId': '2278218736', 'name': 'Fuli Luo'},\n",
       "   {'authorId': '2278217940', 'name': 'Chong Ruan'}],\n",
       "  'doi': '10.48550/arXiv.2408.08152',\n",
       "  'intent': [],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'e1a642026fb46a8b8a868862bcf0728e8d215d7e',\n",
       "  'title': 'DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e1a642026fb46a8b8a868862bcf0728e8d215d7e',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.03350',\n",
       "  'authors': [{'authorId': '2315254065', 'name': 'Jiewen Hu'},\n",
       "   {'authorId': '2315988620', 'name': 'Thomas Zhu'},\n",
       "   {'authorId': '2129663', 'name': 'S. Welleck'}],\n",
       "  'doi': '10.48550/arXiv.2408.03350',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'bef31c928031d0408d1f00c04a07921aef66fff0',\n",
       "  'title': 'miniCTX: Neural Theorem Proving with (Long-)Contexts',\n",
       "  'url': 'https://www.semanticscholar.org/paper/bef31c928031d0408d1f00c04a07921aef66fff0',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2408.01420',\n",
       "  'authors': [{'authorId': '1962384229', 'name': 'Jingtong Su'},\n",
       "   {'authorId': '2268760351', 'name': 'Julia Kempe'},\n",
       "   {'authorId': '2314695668', 'name': 'Karen Ullrich'}],\n",
       "  'doi': '10.48550/arXiv.2408.01420',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '6ed4f005847a08ebe01ee03f9b533fbf860ed197',\n",
       "  'title': 'Mission Impossible: A Statistical Perspective on Jailbreaking LLMs',\n",
       "  'url': 'https://www.semanticscholar.org/paper/6ed4f005847a08ebe01ee03f9b533fbf860ed197',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.18219',\n",
       "  'authors': [{'authorId': '2312907266', 'name': 'Yuxiao Qu'},\n",
       "   {'authorId': '2313179548', 'name': 'Tianjun Zhang'},\n",
       "   {'authorId': '2307473601', 'name': 'Naman Garg'},\n",
       "   {'authorId': '2313046878', 'name': 'Aviral Kumar'}],\n",
       "  'doi': '10.48550/arXiv.2407.18219',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'bdc8c92a44714b468b40ef3d77e96d966f93141b',\n",
       "  'title': 'Recursive Introspection: Teaching Language Model Agents How to Self-Improve',\n",
       "  'url': 'https://www.semanticscholar.org/paper/bdc8c92a44714b468b40ef3d77e96d966f93141b',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.17227',\n",
       "  'authors': [{'authorId': '2283840256', 'name': 'Zijian Wu'},\n",
       "   {'authorId': '2283823680', 'name': 'Jiayu Wang'},\n",
       "   {'authorId': '2261095726', 'name': 'Dahua Lin'},\n",
       "   {'authorId': '2275790072', 'name': 'Kai Chen'}],\n",
       "  'doi': '10.48550/arXiv.2407.17227',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '85c4ada888e7c363e671a6398d8a7b99cf890317',\n",
       "  'title': 'LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN prover',\n",
       "  'url': 'https://www.semanticscholar.org/paper/85c4ada888e7c363e671a6398d8a7b99cf890317',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.12982',\n",
       "  'authors': [{'authorId': '2175557537', 'name': 'To Eun Kim'},\n",
       "   {'authorId': '2073044451', 'name': 'Alireza Salemi'},\n",
       "   {'authorId': '32573794', 'name': 'Andrew Drozdov'},\n",
       "   {'authorId': '2311888401', 'name': 'Fernando Diaz'},\n",
       "   {'authorId': '2295731593', 'name': 'Hamed Zamani'}],\n",
       "  'doi': '10.48550/arXiv.2407.12982',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '9a4a3f8ef868d01c785693634d1ade55b3174dc6',\n",
       "  'title': 'Retrieval-Enhanced Machine Learning: Synthesis and Opportunities',\n",
       "  'url': 'https://www.semanticscholar.org/paper/9a4a3f8ef868d01c785693634d1ade55b3174dc6',\n",
       "  'venue': 'SIGIR-AP',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.12883',\n",
       "  'authors': [{'authorId': '2152173042', 'name': 'Hongjin Su'},\n",
       "   {'authorId': '2287806228', 'name': 'Howard Yen'},\n",
       "   {'authorId': '67284811', 'name': 'Mengzhou Xia'},\n",
       "   {'authorId': '2257597409', 'name': 'Weijia Shi'},\n",
       "   {'authorId': '2037383772', 'name': 'Niklas Muennighoff'},\n",
       "   {'authorId': '2312196704', 'name': 'Han-yu Wang'},\n",
       "   {'authorId': '2312093005', 'name': 'Haisu Liu'},\n",
       "   {'authorId': '2312003525', 'name': 'Quan Shi'},\n",
       "   {'authorId': '2274102473', 'name': 'Zachary S. Siegel'},\n",
       "   {'authorId': '2312099488', 'name': 'Michael Tang'},\n",
       "   {'authorId': '2313049168', 'name': 'Ruoxi Sun'},\n",
       "   {'authorId': '2256335437', 'name': 'Jinsung Yoon'},\n",
       "   {'authorId': '2676352', 'name': 'Sercan Ö. Arik'},\n",
       "   {'authorId': '2311929494', 'name': 'Danqi Chen'},\n",
       "   {'authorId': '2312346274', 'name': 'Tao Yu'}],\n",
       "  'doi': '10.48550/arXiv.2407.12883',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'd79927715a88825737d2ff44f70b1d6698e0bae9',\n",
       "  'title': 'BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval',\n",
       "  'url': 'https://www.semanticscholar.org/paper/d79927715a88825737d2ff44f70b1d6698e0bae9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.11214',\n",
       "  'authors': [{'authorId': '2072570293', 'name': 'G. Tsoukalas'},\n",
       "   {'authorId': '2311551542', 'name': 'Jasper Lee'},\n",
       "   {'authorId': '2311507619', 'name': 'John Jennings'},\n",
       "   {'authorId': '2283305806', 'name': 'Jimmy Xin'},\n",
       "   {'authorId': '2311512457', 'name': 'Michelle Ding'},\n",
       "   {'authorId': '2311507283', 'name': 'Michael Jennings'},\n",
       "   {'authorId': '2070335783', 'name': 'Amitayush Thakur'},\n",
       "   {'authorId': '2248225759', 'name': 'Swarat Chaudhuri'}],\n",
       "  'doi': '10.48550/arXiv.2407.11214',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '6354569d60b80c85b7bd557b80e6d9a5cf719d6e',\n",
       "  'title': 'PutnamBench: Evaluating Neural Theorem-Provers on the Putnam Mathematical Competition',\n",
       "  'url': 'https://www.semanticscholar.org/paper/6354569d60b80c85b7bd557b80e6d9a5cf719d6e',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '1845890183', 'name': 'Sumit Kumar Jha'},\n",
       "   {'authorId': '37747652', 'name': 'Susmit Jha'},\n",
       "   {'authorId': '2321674087', 'name': 'Muhammad Rashedul Haq Rashed'},\n",
       "   {'authorId': '2828546', 'name': 'Rickard Ewetz'},\n",
       "   {'authorId': '2247600091', 'name': 'Alvaro Velasquez'}],\n",
       "  'doi': '10.1109/NAECON61878.2024.10670630',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b904ee841a0c95c3ef1583f93eeefbe80228196e',\n",
       "  'title': 'Automated Synthesis of Hardware Designs using Symbolic Feedback and Grammar-Constrained Decoding in Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b904ee841a0c95c3ef1583f93eeefbe80228196e',\n",
       "  'venue': 'NAECON 2024 - IEEE National Aerospace and Electronics Conference',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.07924',\n",
       "  'authors': [{'authorId': '2154499886', 'name': 'Jihai Zhang'},\n",
       "   {'authorId': '2261647779', 'name': 'Wei Wang'},\n",
       "   {'authorId': '2310774450', 'name': 'Siyan Guo'},\n",
       "   {'authorId': '2214317941', 'name': 'Li Wang'},\n",
       "   {'authorId': '2113698750', 'name': 'Fangquan Lin'},\n",
       "   {'authorId': '2154173571', 'name': 'Cheng Yang'},\n",
       "   {'authorId': '2310701979', 'name': 'Wotao Yin'}],\n",
       "  'doi': '10.18653/v1/2024.naacl-industry.42',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '471cfc2e3239ee4e67591a8b765a27248d6a60a8',\n",
       "  'title': 'Solving General Natural-Language-Description Optimization Problems with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/471cfc2e3239ee4e67591a8b765a27248d6a60a8',\n",
       "  'venue': 'NAACL',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.14521',\n",
       "  'authors': [{'authorId': '2312325249', 'name': 'Mahdi Buali'},\n",
       "   {'authorId': '1798963', 'name': 'R. Hoehndorf'}],\n",
       "  'doi': '10.48550/arXiv.2407.14521',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a6910309c70c5dbd604431993d7c2d0001886424',\n",
       "  'title': 'Towards Automated Functional Equation Proving: A Benchmark Dataset and A Domain-Specific In-Context Agent',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a6910309c70c5dbd604431993d7c2d0001886424',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.00695',\n",
       "  'authors': [{'authorId': '2113249490', 'name': 'Gabriel Poesia'},\n",
       "   {'authorId': '2309177826', 'name': 'David Broman'},\n",
       "   {'authorId': '2239093653', 'name': 'Nick Haber'},\n",
       "   {'authorId': '2265069313', 'name': 'Noah D. Goodman'}],\n",
       "  'doi': '10.48550/arXiv.2407.00695',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '91b417ae72ad1ffc6dc6f84e09839e9fc4cef420',\n",
       "  'title': 'Learning Formal Mathematics From Intrinsic Motivation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/91b417ae72ad1ffc6dc6f84e09839e9fc4cef420',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.18616',\n",
       "  'authors': [{'authorId': '2288291622', 'name': 'Yufan Cai'},\n",
       "   {'authorId': '2267761050', 'name': 'Zhe Hou'},\n",
       "   {'authorId': '2308469199', 'name': 'Xiaokun Luan'},\n",
       "   {'authorId': '39774521', 'name': 'David Sanán'},\n",
       "   {'authorId': '2268019310', 'name': 'Yun Lin'},\n",
       "   {'authorId': '2261694236', 'name': 'Jun Sun'},\n",
       "   {'authorId': '2301410525', 'name': 'Jin Song Dong'}],\n",
       "  'doi': '10.48550/arXiv.2406.18616',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '3524666f03e5a253192ecfe967c4575e364fceb9',\n",
       "  'title': 'Towards Large Language Model Aided Program Refinement',\n",
       "  'url': 'https://www.semanticscholar.org/paper/3524666f03e5a253192ecfe967c4575e364fceb9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.16838',\n",
       "  'authors': [{'authorId': '2129663', 'name': 'S. Welleck'},\n",
       "   {'authorId': '2138301112', 'name': 'Amanda Bertsch'},\n",
       "   {'authorId': '1580418311', 'name': 'Matthew Finlayson'},\n",
       "   {'authorId': '2184031883', 'name': 'Hailey Schoelkopf'},\n",
       "   {'authorId': '2253395527', 'name': 'Alex Xie'},\n",
       "   {'authorId': '2265547593', 'name': 'Graham Neubig'},\n",
       "   {'authorId': '2308102420', 'name': 'Ilia Kulikov'},\n",
       "   {'authorId': '2265540561', 'name': 'Zaid Harchaoui'}],\n",
       "  'doi': '10.48550/arXiv.2406.16838',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '99b38b72026775a1e91d83fb71e984b5e8b7b374',\n",
       "  'title': 'From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/99b38b72026775a1e91d83fb71e984b5e8b7b374',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.16176',\n",
       "  'authors': [{'authorId': '2308071041', 'name': 'Qiming Wu'},\n",
       "   {'authorId': '2266978057', 'name': 'Zichen Chen'},\n",
       "   {'authorId': '2308034303', 'name': 'Will Corcoran'},\n",
       "   {'authorId': '3024298', 'name': 'Misha Sra'},\n",
       "   {'authorId': '2267221564', 'name': 'Ambuj Singh'}],\n",
       "  'doi': '10.48550/arXiv.2406.16176',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '3b2c8438d67f0ed2bd381ed0808fe5d68a3750bd',\n",
       "  'title': 'GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets',\n",
       "  'url': 'https://www.semanticscholar.org/paper/3b2c8438d67f0ed2bd381ed0808fe5d68a3750bd',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.15540',\n",
       "  'authors': [{'authorId': '2308031420', 'name': 'George Granberry'},\n",
       "   {'authorId': '2308032813', 'name': 'Wolfgang Ahrendt'},\n",
       "   {'authorId': '2308031392', 'name': 'Moa Johansson'}],\n",
       "  'doi': '10.48550/arXiv.2406.15540',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4d84b3231cdc12b13f961d2024cfb0e7903f0b30',\n",
       "  'title': 'Specify What? Enhancing Neural Specification Synthesis by Symbolic Methods',\n",
       "  'url': 'https://www.semanticscholar.org/paper/4d84b3231cdc12b13f961d2024cfb0e7903f0b30',\n",
       "  'venue': 'IFM',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.14408',\n",
       "  'authors': [{'authorId': '2284323840', 'name': 'Xiaohan Lin'},\n",
       "   {'authorId': '2249759360', 'name': 'Qingxing Cao'},\n",
       "   {'authorId': '2303470248', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '2302633318', 'name': 'Jianqiao Lu'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2284235236', 'name': 'Linqi Song'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'}],\n",
       "  'doi': '10.48550/arXiv.2406.14408',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a761358b3b858f84abe76b7938b74c387dcf4899',\n",
       "  'title': 'FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a761358b3b858f84abe76b7938b74c387dcf4899',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.14219',\n",
       "  'authors': [{'authorId': '2307739969', 'name': 'Chenrui Wei'},\n",
       "   {'authorId': '2308815385', 'name': 'Mengzhou Sun'},\n",
       "   {'authorId': '2307556017', 'name': 'Wei Wang'}],\n",
       "  'doi': '10.48550/arXiv.2406.14219',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'c430d9b478ae93c5bb2d197c607fcacb9c8b0e22',\n",
       "  'title': 'Proving Olympiad Algebraic Inequalities without Human Demonstrations',\n",
       "  'url': 'https://www.semanticscholar.org/paper/c430d9b478ae93c5bb2d197c607fcacb9c8b0e22',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.11915',\n",
       "  'authors': [{'authorId': '2307080043', 'name': 'Evan Lohn'},\n",
       "   {'authorId': '2129663', 'name': 'S. Welleck'}],\n",
       "  'doi': '10.48550/arXiv.2406.11915',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'fac63247eebc933c19c8de2809ec68d9c957e6e3',\n",
       "  'title': 'miniCodeProps: a Minimal Benchmark for Proving Code Properties',\n",
       "  'url': 'https://www.semanticscholar.org/paper/fac63247eebc933c19c8de2809ec68d9c957e6e3',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.06140',\n",
       "  'authors': [{'authorId': '2261884659', 'name': 'Zhiquan Tan'},\n",
       "   {'authorId': '2281903333', 'name': 'Lai Wei'},\n",
       "   {'authorId': '2281902732', 'name': 'Jindong Wang'},\n",
       "   {'authorId': '2249681654', 'name': 'Xing Xie'},\n",
       "   {'authorId': '2304597232', 'name': 'Weiran Huang'}],\n",
       "  'doi': '10.48550/arXiv.2406.06140',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'edea43a7a0e181f6d26b358969578d5b8869bfb0',\n",
       "  'title': 'Can I understand what I create? Self-Knowledge Evaluation of Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/edea43a7a0e181f6d26b358969578d5b8869bfb0',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.05498',\n",
       "  'authors': [{'authorId': '2269512288', 'name': 'Xunguang Wang'},\n",
       "   {'authorId': '2253859864', 'name': 'Daoyuan Wu'},\n",
       "   {'authorId': '1899405856', 'name': 'Zhenlan Ji'},\n",
       "   {'authorId': '2118207559', 'name': 'Zongjie Li'},\n",
       "   {'authorId': '1384480816', 'name': 'Pingchuan Ma'},\n",
       "   {'authorId': '2275762958', 'name': 'Shuaibao Wang'},\n",
       "   {'authorId': '2305625014', 'name': 'Yingjiu Li'},\n",
       "   {'authorId': '2281790097', 'name': 'Yang Liu'},\n",
       "   {'authorId': '2287807030', 'name': 'Ning Liu'},\n",
       "   {'authorId': '2305615710', 'name': 'Juergen Rahmel'}],\n",
       "  'doi': '10.48550/arXiv.2406.05498',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'cc9858f27dbc4e766e467fba706fa252154490cd',\n",
       "  'title': 'SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner',\n",
       "  'url': 'https://www.semanticscholar.org/paper/cc9858f27dbc4e766e467fba706fa252154490cd',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.01940',\n",
       "  'authors': [{'authorId': '2302633318', 'name': 'Jianqiao Lu'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2303955786', 'name': 'Yingjia Wan'},\n",
       "   {'authorId': '2303470248', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '50109597', 'name': 'Zhicheng YANG'},\n",
       "   {'authorId': '2255480255', 'name': 'Jing Tang'},\n",
       "   {'authorId': '2681038', 'name': 'Zhijiang Guo'}],\n",
       "  'doi': '10.48550/arXiv.2406.01940',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'db0f9376882cf7805f36def33600805d330e5386',\n",
       "  'title': 'Process-Driven Autoformalization in Lean 4',\n",
       "  'url': 'https://www.semanticscholar.org/paper/db0f9376882cf7805f36def33600805d330e5386',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2406.02746',\n",
       "  'authors': [{'authorId': '2304897819', 'name': 'Jinghan Zhang'},\n",
       "   {'authorId': '2304896765', 'name': 'Xiting Wang'},\n",
       "   {'authorId': '22500310', 'name': 'Weijieying Ren'},\n",
       "   {'authorId': '2304822381', 'name': 'Lu Jiang'},\n",
       "   {'authorId': '1669829502', 'name': 'Dongjie Wang'},\n",
       "   {'authorId': '2238129790', 'name': 'Kunpeng Liu'}],\n",
       "  'doi': '10.48550/arXiv.2406.02746',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f696ffb1f0408e06ab4d91985f3e3f837c370c77',\n",
       "  'title': 'RATT: A Thought Structure for Coherent and Correct LLM Reasoning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f696ffb1f0408e06ab4d91985f3e3f837c370c77',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.16933',\n",
       "  'authors': [{'authorId': '2268495952', 'name': 'Xun Liang'},\n",
       "   {'authorId': '2268393907', 'name': 'Simin Niu'},\n",
       "   {'authorId': '2268429641', 'name': 'Zhiyu Li'},\n",
       "   {'authorId': '2107969558', 'name': 'Sensen Zhang'},\n",
       "   {'authorId': '2268434524', 'name': 'Shichao Song'},\n",
       "   {'authorId': '2284861141', 'name': 'Hanyu Wang'},\n",
       "   {'authorId': '2303425635', 'name': 'Jiawei Yang'},\n",
       "   {'authorId': '2268399953', 'name': 'Feiyu Xiong'},\n",
       "   {'authorId': '2268400606', 'name': 'Bo Tang'},\n",
       "   {'authorId': '2303402664', 'name': 'Chenyang Xi'}],\n",
       "  'doi': '10.48550/arXiv.2405.16933',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a4d4fb5aa23a8eee7a77b5911803593eacbb4e06',\n",
       "  'title': 'Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a4d4fb5aa23a8eee7a77b5911803593eacbb4e06',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.17216',\n",
       "  'authors': [{'authorId': '2296711588', 'name': 'Logan Murphy'},\n",
       "   {'authorId': '2297821506', 'name': 'Kaiyu Yang'},\n",
       "   {'authorId': '2296735131', 'name': 'Jialiang Sun'},\n",
       "   {'authorId': '2288036658', 'name': 'Zhaoyu Li'},\n",
       "   {'authorId': '2257161858', 'name': 'A. Anandkumar'},\n",
       "   {'authorId': '2249532070', 'name': 'Xujie Si'}],\n",
       "  'doi': '10.48550/arXiv.2405.17216',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'be569bb1134e113904893023807dfdb15b75f31e',\n",
       "  'title': 'Autoformalizing Euclidean Geometry',\n",
       "  'url': 'https://www.semanticscholar.org/paper/be569bb1134e113904893023807dfdb15b75f31e',\n",
       "  'venue': 'ICML',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.16792',\n",
       "  'authors': [{'authorId': '2288095455', 'name': 'Eric Mugnier'},\n",
       "   {'authorId': '2303438153', 'name': 'Emmanuel Anaya Gonzalez'},\n",
       "   {'authorId': '143944551', 'name': 'Ranjit Jhala'},\n",
       "   {'authorId': '2258443511', 'name': 'Nadia Polikarpova'},\n",
       "   {'authorId': '2288167196', 'name': 'Yuanyuan Zhou'}],\n",
       "  'doi': '10.48550/arXiv.2405.16792',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'cf4cbd02cc57c7f4487b30d6884d4d6841d627a8',\n",
       "  'title': 'Laurel: Generating Dafny Assertions Using Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/cf4cbd02cc57c7f4487b30d6884d4d6841d627a8',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.15722',\n",
       "  'authors': [{'authorId': '2217545709', 'name': 'Noga Amit'},\n",
       "   {'authorId': '73772011', 'name': 'Orr Paradise'},\n",
       "   {'authorId': '2551824', 'name': 'G. Rothblum'},\n",
       "   {'authorId': '1706681', 'name': 'S. Goldwasser'}],\n",
       "  'doi': '10.48550/arXiv.2405.15722',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '34d30f8997ea244204cc07d83dca9468a2005cc9',\n",
       "  'title': 'Models That Prove Their Own Correctness',\n",
       "  'url': 'https://www.semanticscholar.org/paper/34d30f8997ea244204cc07d83dca9468a2005cc9',\n",
       "  'venue': 'Electron. Colloquium Comput. Complex.',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.14414',\n",
       "  'authors': [{'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '2238628841', 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2302811596', 'name': 'Wenda Li'},\n",
       "   {'authorId': '153268218', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2302633318', 'name': 'Jianqiao Lu'},\n",
       "   {'authorId': '50109597', 'name': 'Zhicheng YANG'},\n",
       "   {'authorId': '2255480255', 'name': 'Jing Tang'},\n",
       "   {'authorId': '2249872910', 'name': 'Jian Yin'},\n",
       "   {'authorId': '2249755860', 'name': 'Zhenguo Li'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'}],\n",
       "  'doi': '10.48550/arXiv.2405.14414',\n",
       "  'intent': [],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '29d2bf6d4b0ce5cdd2cf0ad3103597ba5681f29f',\n",
       "  'title': 'Proving Theorems Recursively',\n",
       "  'url': 'https://www.semanticscholar.org/paper/29d2bf6d4b0ce5cdd2cf0ad3103597ba5681f29f',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.14333',\n",
       "  'authors': [{'authorId': '2238628841', 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2303510276', 'name': 'Daya Guo'},\n",
       "   {'authorId': '2302778018', 'name': 'Zhihong Shao'},\n",
       "   {'authorId': '2304140796', 'name': 'Z. Ren'},\n",
       "   {'authorId': '2278223869', 'name': 'Qihao Zhu'},\n",
       "   {'authorId': '2156640188', 'name': 'Bo Liu (Benjamin Liu)'},\n",
       "   {'authorId': '2278217940', 'name': 'Chong Ruan'},\n",
       "   {'authorId': '2302811596', 'name': 'Wenda Li'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'}],\n",
       "  'doi': '10.48550/arXiv.2405.14333',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '3648515cc35b517cdf60331cc4870e24616f9939',\n",
       "  'title': 'DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data',\n",
       "  'url': 'https://www.semanticscholar.org/paper/3648515cc35b517cdf60331cc4870e24616f9939',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.08863',\n",
       "  'authors': [{'authorId': '2301312107', 'name': 'Joseph Tooby-Smith'}],\n",
       "  'doi': '10.48550/arXiv.2405.08863',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '9275e5fedcb42d218766fa1388aa96f7adc20bc0',\n",
       "  'title': 'HepLean: Digitalising high energy physics',\n",
       "  'url': 'https://www.semanticscholar.org/paper/9275e5fedcb42d218766fa1388aa96f7adc20bc0',\n",
       "  'venue': 'Computer Physics Communications',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.07460',\n",
       "  'authors': [{'authorId': '2164093525', 'name': 'Aakash Tripathi'},\n",
       "   {'authorId': '2053769148', 'name': 'Asim Waqas'},\n",
       "   {'authorId': '2253461909', 'name': 'Yasin Yilmaz'},\n",
       "   {'authorId': '2248117335', 'name': 'Ghulam Rasool'}],\n",
       "  'doi': '10.48550/arXiv.2405.07460',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4517e89877f2b42b6c3e2fa4517c4b01b1add33b',\n",
       "  'title': 'HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/4517e89877f2b42b6c3e2fa4517c4b01b1add33b',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.06677',\n",
       "  'authors': [{'authorId': '2284323840', 'name': 'Xiaohan Lin'},\n",
       "   {'authorId': '2249759360', 'name': 'Qingxing Cao'},\n",
       "   {'authorId': '153268218', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '50109597', 'name': 'Zhicheng YANG'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2249755860', 'name': 'Zhenguo Li'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'}],\n",
       "  'doi': '10.48550/arXiv.2405.06677',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '2f85aa1f80c944d2a167262e38fb9d0611e4dc7f',\n",
       "  'title': 'ATG: Benchmarking Automated Theorem Generation for Generative Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/2f85aa1f80c944d2a167262e38fb9d0611e4dc7f',\n",
       "  'venue': 'NAACL-HLT',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.01787',\n",
       "  'authors': [{'authorId': '2253471013', 'name': 'Saikat Chakraborty'},\n",
       "   {'authorId': '2299942574', 'name': 'Gabriel Ebner'},\n",
       "   {'authorId': '2299940419', 'name': 'Siddharth Bhat'},\n",
       "   {'authorId': '2253466024', 'name': 'Sarah Fakhoury'},\n",
       "   {'authorId': '2299942397', 'name': 'Sakina Fatima'},\n",
       "   {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'},\n",
       "   {'authorId': '2258712735', 'name': 'Nikhil Swamy'}],\n",
       "  'doi': '10.48550/arXiv.2405.01787',\n",
       "  'intent': ['result', 'background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'a0ae5c05d0417d4e0fac8373787bb41b9e27d7d0',\n",
       "  'title': 'Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a0ae5c05d0417d4e0fac8373787bb41b9e27d7d0',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2405.03709',\n",
       "  'authors': [{'authorId': '21120197', 'name': 'Karim Elmaaroufi'},\n",
       "   {'authorId': '2300173739', 'name': 'Devan Shankar'},\n",
       "   {'authorId': '2300174198', 'name': 'Ana Cismaru'},\n",
       "   {'authorId': '1399245394', 'name': 'Marcell Vazquez-Chanlatte'},\n",
       "   {'authorId': '1400646910', 'name': 'A. Sangiovanni-Vincentelli'},\n",
       "   {'authorId': '2253469012', 'name': 'Matei Zaharia'},\n",
       "   {'authorId': '1775517', 'name': 'S. Seshia'}],\n",
       "  'doi': '10.48550/arXiv.2405.03709',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'e7b924757176fd5eca61d50b182775b1e5114d7b',\n",
       "  'title': 'Generating Probabilistic Scenario Programs from Natural Language',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e7b924757176fd5eca61d50b182775b1e5114d7b',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2407.10237',\n",
       "  'authors': [{'authorId': '2293329450', 'name': 'Christian Clemm'},\n",
       "   {'authorId': '2311433522', 'name': 'Lutz Stobbe'},\n",
       "   {'authorId': '3058935', 'name': 'Kishan Wimalawarne'},\n",
       "   {'authorId': '2036791157', 'name': 'Jan Druschke'}],\n",
       "  'doi': '10.23919/EGG62010.2024.10631247',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '657c0443827055455c26ab1d0e9f3dc56f780c9a',\n",
       "  'title': 'Towards Green AI: Current Status and Future Research',\n",
       "  'url': 'https://www.semanticscholar.org/paper/657c0443827055455c26ab1d0e9f3dc56f780c9a',\n",
       "  'venue': '2024 Electronics Goes Green 2024+ (EGG)',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.18400',\n",
       "  'authors': [{'authorId': '2037848556', 'name': 'Parshin Shojaee'},\n",
       "   {'authorId': '1999900316', 'name': 'Kazem Meidani'},\n",
       "   {'authorId': '2152953535', 'name': 'Shashank Gupta'},\n",
       "   {'authorId': '3614493', 'name': 'A. Farimani'},\n",
       "   {'authorId': '2262444977', 'name': 'Chandan K. Reddy'}],\n",
       "  'doi': '10.48550/arXiv.2404.18400',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '860ba78f9789bbfc99c299b18558ca19430d8fea',\n",
       "  'title': 'LLM-SR: Scientific Equation Discovery via Programming with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/860ba78f9789bbfc99c299b18558ca19430d8fea',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.12534',\n",
       "  'authors': [{'authorId': '2297671110', 'name': 'Peiyang Song'},\n",
       "   {'authorId': '2297821506', 'name': 'Kaiyu Yang'},\n",
       "   {'authorId': '2257161858', 'name': 'A. Anandkumar'}],\n",
       "  'doi': '10.48550/arXiv.2404.12534',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '91ca6535fc8fb03efe0ecbe424ce5354ed129b0c',\n",
       "  'title': 'Towards Large Language Models as Copilots for Theorem Proving in Lean',\n",
       "  'url': 'https://www.semanticscholar.org/paper/91ca6535fc8fb03efe0ecbe424ce5354ed129b0c',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.11276',\n",
       "  'authors': [{'authorId': '2297137653', 'name': 'Haotian Chen'},\n",
       "   {'authorId': '2297131415', 'name': 'Xinjie Shen'},\n",
       "   {'authorId': '2260317749', 'name': 'Zeqi Ye'},\n",
       "   {'authorId': '2313613916', 'name': 'Wenjun Feng'},\n",
       "   {'authorId': '2313536424', 'name': 'Haoxue Wang'},\n",
       "   {'authorId': '2112096484', 'name': 'Xiao Yang'},\n",
       "   {'authorId': '2260276776', 'name': 'Xu Yang'},\n",
       "   {'authorId': '1390517481', 'name': 'Weiqing Liu'},\n",
       "   {'authorId': '2258957328', 'name': 'Jiang Bian'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '8aa6f277be2c65243d1f52f41dc7ef293129c9e9',\n",
       "  'title': 'Towards Data-Centric Automatic R&D',\n",
       "  'url': 'https://www.semanticscholar.org/paper/8aa6f277be2c65243d1f52f41dc7ef293129c9e9',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.09939',\n",
       "  'authors': [{'authorId': '2288036658', 'name': 'Zhaoyu Li'},\n",
       "   {'authorId': '2296735131', 'name': 'Jialiang Sun'},\n",
       "   {'authorId': '2296711588', 'name': 'Logan Murphy'},\n",
       "   {'authorId': '2262446456', 'name': 'Qidong Su'},\n",
       "   {'authorId': '2296961214', 'name': 'Zenan Li'},\n",
       "   {'authorId': '2328001745', 'name': 'Xian Zhang'},\n",
       "   {'authorId': '2297821506', 'name': 'Kaiyu Yang'},\n",
       "   {'authorId': '2249532070', 'name': 'Xujie Si'}],\n",
       "  'doi': '10.48550/arXiv.2404.09939',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '6a4501fefaf73261dc180ff86b52208679f3fb9c',\n",
       "  'title': 'A Survey on Deep Learning for Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/6a4501fefaf73261dc180ff86b52208679f3fb9c',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.07382',\n",
       "  'authors': [{'authorId': '2295988926', 'name': 'Chenyang An'},\n",
       "   {'authorId': '2296028330', 'name': 'Zhibo Chen'},\n",
       "   {'authorId': '2295990997', 'name': 'Qihao Ye'},\n",
       "   {'authorId': '2295988294', 'name': 'Emily First'},\n",
       "   {'authorId': '2265617343', 'name': 'Letian Peng'},\n",
       "   {'authorId': '2266421485', 'name': 'Jiayun Zhang'},\n",
       "   {'authorId': '2255392606', 'name': 'Zihan Wang'},\n",
       "   {'authorId': '2295988080', 'name': 'Sorin Lerner'},\n",
       "   {'authorId': '2254284383', 'name': 'Jingbo Shang'}],\n",
       "  'doi': '10.48550/arXiv.2404.07382',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'adfac93d6b6ccc9a83e2e37c337f1cb9c69392df',\n",
       "  'title': 'Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/adfac93d6b6ccc9a83e2e37c337f1cb9c69392df',\n",
       "  'venue': 'ACL',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.05778',\n",
       "  'authors': [{'authorId': '2288490566', 'name': 'Steven Clontz'}],\n",
       "  'doi': '10.48550/arXiv.2404.05778',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '42183a622ee853f4caeb3d93ebddbb33fda3f30e',\n",
       "  'title': 'Database-Driven Mathematical Inquiry',\n",
       "  'url': 'https://www.semanticscholar.org/paper/42183a622ee853f4caeb3d93ebddbb33fda3f30e',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.01554',\n",
       "  'authors': [{'authorId': '2290464625', 'name': 'Qi Guo'},\n",
       "   {'authorId': '2118890600', 'name': 'Xiaohong Li'},\n",
       "   {'authorId': '2288741802', 'name': 'Xiaofei Xie'},\n",
       "   {'authorId': '2290359321', 'name': 'Shangqing Liu'},\n",
       "   {'authorId': '2109915677', 'name': 'Ze Tang'},\n",
       "   {'authorId': '1758019', 'name': 'Ruitao Feng'},\n",
       "   {'authorId': '2294667814', 'name': 'Junjie Wang'},\n",
       "   {'authorId': '2294564180', 'name': 'Jidong Ge'},\n",
       "   {'authorId': '2279752248', 'name': 'Lei Bu'}],\n",
       "  'doi': '10.1145/3650212.3652130',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '16b5ccdd6e5c10e4379000162e4608bea2274a5b',\n",
       "  'title': 'FT2Ra: A Fine-Tuning-Inspired Approach to Retrieval-Augmented Code Completion',\n",
       "  'url': 'https://www.semanticscholar.org/paper/16b5ccdd6e5c10e4379000162e4608bea2274a5b',\n",
       "  'venue': 'ISSTA',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2404.00762',\n",
       "  'authors': [{'authorId': '2294360584', 'name': 'Cheng Wen'},\n",
       "   {'authorId': '51170803', 'name': 'Jialun Cao'},\n",
       "   {'authorId': '2268827043', 'name': 'Jie Su'},\n",
       "   {'authorId': '2290622075', 'name': 'Zhiwu Xu'},\n",
       "   {'authorId': '2268205001', 'name': 'Shengchao Qin'},\n",
       "   {'authorId': '3387261', 'name': 'Mengda He'},\n",
       "   {'authorId': '2294686625', 'name': 'Haokun Li'},\n",
       "   {'authorId': '143608708', 'name': 'S. Cheung'},\n",
       "   {'authorId': '2293844213', 'name': 'Cong Tian'}],\n",
       "  'doi': '10.48550/arXiv.2404.00762',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'e8cbe2279dcfa4a76642090a935deec9abff7e6e',\n",
       "  'title': 'Enchanting Program Specification Synthesis by Large Language Models using Static Analysis and Program Verification',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e8cbe2279dcfa4a76642090a935deec9abff7e6e',\n",
       "  'venue': 'CAV',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.18327',\n",
       "  'authors': [{'authorId': '72254820', 'name': 'Rushang Karia'},\n",
       "   {'authorId': '1387180660', 'name': 'D. Dobhal'},\n",
       "   {'authorId': '2293614312', 'name': 'Daniel Bramblett'},\n",
       "   {'authorId': '39765564', 'name': 'Pulkit Verma'},\n",
       "   {'authorId': '2283933883', 'name': 'Siddharth Srivastava'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a5f8d778c85f2bb6b9bd1d30386795d4b8c76294',\n",
       "  'title': '$\\\\forall$uto$\\\\exists$val: Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a5f8d778c85f2bb6b9bd1d30386795d4b8c76294',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.13312',\n",
       "  'authors': [{'authorId': '2292347517', 'name': 'Dongwei Jiang'},\n",
       "   {'authorId': '2266753090', 'name': 'Marcio Fonseca'},\n",
       "   {'authorId': '2277600097', 'name': 'Shay B. Cohen'}],\n",
       "  'doi': '10.48550/arXiv.2403.13312',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '8f8e46b7d454406ec35358f525ce9ce17ff3f2b0',\n",
       "  'title': 'LeanReasoner: Boosting Complex Logical Reasoning with Lean',\n",
       "  'url': 'https://www.semanticscholar.org/paper/8f8e46b7d454406ec35358f525ce9ce17ff3f2b0',\n",
       "  'venue': 'NAACL',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.11322',\n",
       "  'authors': [{'authorId': '2115853457', 'name': 'Yiran Wu'},\n",
       "   {'authorId': '2292030487', 'name': 'Tianwei Yue'},\n",
       "   {'authorId': '2116579935', 'name': 'Shaokun Zhang'},\n",
       "   {'authorId': '2256289554', 'name': 'Chi Wang'},\n",
       "   {'authorId': '2254166618', 'name': 'Qingyun Wu'}],\n",
       "  'doi': '10.48550/arXiv.2403.11322',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b8cc74d8c2a009cc99a8b285503d86be80d840d9',\n",
       "  'title': 'StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b8cc74d8c2a009cc99a8b285503d86be80d840d9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.04017',\n",
       "  'authors': [{'authorId': '1585458992', 'name': 'Lasse Blaauwbroek'},\n",
       "   {'authorId': '2290181461', 'name': 'David M. Cerna'},\n",
       "   {'authorId': '37734149', 'name': 'Thibault Gauthier'},\n",
       "   {'authorId': '2164124168', 'name': 'Jan Jakubruv'},\n",
       "   {'authorId': '1784106', 'name': 'C. Kaliszyk'},\n",
       "   {'authorId': '2290181225', 'name': 'Martin Suda'},\n",
       "   {'authorId': '2239120378', 'name': 'Josef Urban'}],\n",
       "  'doi': '10.48550/arXiv.2403.04017',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'edd3e9d9347a3866e1a5a913733f1d9477ec7a2c',\n",
       "  'title': 'Learning Guided Automated Reasoning: A Brief Survey',\n",
       "  'url': 'https://www.semanticscholar.org/paper/edd3e9d9347a3866e1a5a913733f1d9477ec7a2c',\n",
       "  'venue': 'Logics and Type Systems in Theory and Practice',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.03187',\n",
       "  'authors': [{'authorId': '35584853', 'name': 'Akari Asai'},\n",
       "   {'authorId': '49164966', 'name': 'Zexuan Zhong'},\n",
       "   {'authorId': '50536468', 'name': 'Danqi Chen'},\n",
       "   {'authorId': '2303396379', 'name': 'Pang Wei Koh'},\n",
       "   {'authorId': '2137813791', 'name': 'Luke S. Zettlemoyer'},\n",
       "   {'authorId': '2264251662', 'name': 'Hanna Hajishirzi'},\n",
       "   {'authorId': '2072801764', 'name': 'Wen-tau Yih'}],\n",
       "  'doi': '10.48550/arXiv.2403.03187',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'cfa85c8db829dbd2384ea7f130f462e7e7f1f630',\n",
       "  'title': 'Reliable, Adaptable, and Attributable Language Models with Retrieval',\n",
       "  'url': 'https://www.semanticscholar.org/paper/cfa85c8db829dbd2384ea7f130f462e7e7f1f630',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2403.01632',\n",
       "  'authors': [{'authorId': '1413931779', 'name': 'Shubham Ugare'},\n",
       "   {'authorId': '2218724103', 'name': 'Tarun Suresh'},\n",
       "   {'authorId': '2290027391', 'name': 'Hangoo Kang'},\n",
       "   {'authorId': '1704478', 'name': 'Sasa Misailovic'},\n",
       "   {'authorId': '2258717743', 'name': 'Gagandeep Singh'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '46a41357eadac1459c81588136c5c053abfeefe4',\n",
       "  'title': 'SynCode: LLM Generation with Grammar Augmentation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/46a41357eadac1459c81588136c5c053abfeefe4',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.19446',\n",
       "  'authors': [{'authorId': '2288585404', 'name': 'Yifei Zhou'},\n",
       "   {'authorId': '2288537572', 'name': 'Andrea Zanette'},\n",
       "   {'authorId': '2152946868', 'name': 'Jiayi Pan'},\n",
       "   {'authorId': '2268967207', 'name': 'Sergey Levine'},\n",
       "   {'authorId': '1488785534', 'name': 'Aviral Kumar'}],\n",
       "  'doi': '10.48550/arXiv.2402.19446',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '668858489bbec3ce45f7a84a6a557b329f9ec91a',\n",
       "  'title': 'ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL',\n",
       "  'url': 'https://www.semanticscholar.org/paper/668858489bbec3ce45f7a84a6a557b329f9ec91a',\n",
       "  'venue': 'ICML',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.19473',\n",
       "  'authors': [{'authorId': '2268718776', 'name': 'Penghao Zhao'},\n",
       "   {'authorId': '2288557803', 'name': 'Hailin Zhang'},\n",
       "   {'authorId': '2289597580', 'name': 'Qinhan Yu'},\n",
       "   {'authorId': '2288675277', 'name': 'Zhengren Wang'},\n",
       "   {'authorId': '2288532368', 'name': 'Yunteng Geng'},\n",
       "   {'authorId': '46182701', 'name': 'Fangcheng Fu'},\n",
       "   {'authorId': '2249513224', 'name': 'Ling Yang'},\n",
       "   {'authorId': '2277807793', 'name': 'Wentao Zhang'},\n",
       "   {'authorId': '2277742543', 'name': 'Bin Cui'}],\n",
       "  'doi': '10.48550/arXiv.2402.19473',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'ab15463babf98fffc6f683fe2026de0725b5e1a9',\n",
       "  'title': 'Retrieval-Augmented Generation for AI-Generated Content: A Survey',\n",
       "  'url': 'https://www.semanticscholar.org/paper/ab15463babf98fffc6f683fe2026de0725b5e1a9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.17671',\n",
       "  'authors': [{'authorId': '2267505808', 'name': 'Yunpeng Huang'},\n",
       "   {'authorId': '2287794377', 'name': 'Yaonan Gu'},\n",
       "   {'authorId': '2158383105', 'name': 'Jingwei Xu'},\n",
       "   {'authorId': '2284729046', 'name': 'Zhihong Zhu'},\n",
       "   {'authorId': '2284854420', 'name': 'Zhaorun Chen'},\n",
       "   {'authorId': '2267813458', 'name': 'Xiaoxing Ma'}],\n",
       "  'doi': '10.48550/arXiv.2402.17671',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f144e2a41f3b657831b1885fa3922124a68675b9',\n",
       "  'title': 'Securing Reliability: A Brief Overview on Enhancing In-Context Learning for Foundation Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f144e2a41f3b657831b1885fa3922124a68675b9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.17032',\n",
       "  'authors': [{'authorId': '2287813125', 'name': 'Jin Peng Zhou'},\n",
       "   {'authorId': '2287780080', 'name': 'Yuhuai Wu'},\n",
       "   {'authorId': '2287864957', 'name': 'Qiyang Li'},\n",
       "   {'authorId': '2302321426', 'name': 'Roger Grosse'}],\n",
       "  'doi': '10.48550/arXiv.2402.17032',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '5e7999443d37916269db5ff758587335335ff75d',\n",
       "  'title': 'REFACTOR: Learning to Extract Theorems from Proofs',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5e7999443d37916269db5ff758587335335ff75d',\n",
       "  'venue': 'ICLR',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.16181',\n",
       "  'authors': [{'authorId': '2145522248', 'name': 'Shenao Zhang'},\n",
       "   {'authorId': '2276707810', 'name': 'Sirui Zheng'},\n",
       "   {'authorId': '2249534528', 'name': 'Shuqi Ke'},\n",
       "   {'authorId': '2249539089', 'name': 'Zhihan Liu'},\n",
       "   {'authorId': '2288070836', 'name': 'Wanxin Jin'},\n",
       "   {'authorId': '2257015367', 'name': 'Jianbo Yuan'},\n",
       "   {'authorId': '2257087612', 'name': 'Yingxiang Yang'},\n",
       "   {'authorId': '2212243155', 'name': 'Hongxia Yang'},\n",
       "   {'authorId': '2257245348', 'name': 'Zhaoran Wang'}],\n",
       "  'doi': '10.48550/arXiv.2402.16181',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b42713664a72410307839fe44ec51aef8d69c943',\n",
       "  'title': 'How Can LLM Guide RL? A Value-Based Approach',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b42713664a72410307839fe44ec51aef8d69c943',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.17786',\n",
       "  'authors': [{'authorId': '2288066854', 'name': 'Zilong Zhao'},\n",
       "   {'authorId': '2057815422', 'name': 'Yao Rong'},\n",
       "   {'authorId': '2289089014', 'name': 'Dongyang Guo'},\n",
       "   {'authorId': '2293273586', 'name': 'Emek Gözlüklü'},\n",
       "   {'authorId': '2293273062', 'name': 'Emir Gülboy'},\n",
       "   {'authorId': '1884159', 'name': 'Enkelejda Kasneci'}],\n",
       "  'doi': '10.48550/arXiv.2402.17786',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '5b5ae9ad94b4c0021349d9a6df17c7b2ddf4b111',\n",
       "  'title': 'Stepwise Self-Consistent Mathematical Reasoning with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/5b5ae9ad94b4c0021349d9a6df17c7b2ddf4b111',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.15727',\n",
       "  'authors': [{'authorId': '2253859864', 'name': 'Daoyuan Wu'},\n",
       "   {'authorId': '2275762958', 'name': 'Shuaibao Wang'},\n",
       "   {'authorId': '2281790097', 'name': 'Yang Liu'},\n",
       "   {'authorId': '2287807030', 'name': 'Ning Liu'}],\n",
       "  'doi': '10.48550/arXiv.2402.15727',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '97c203e47b8fd987b6a2e7505669e3b9ae9a147d',\n",
       "  'title': 'LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper',\n",
       "  'url': 'https://www.semanticscholar.org/paper/97c203e47b8fd987b6a2e7505669e3b9ae9a147d',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.15929',\n",
       "  'authors': [{'authorId': '2275249344', 'name': 'Isha Chaudhary'},\n",
       "   {'authorId': '2286879166', 'name': 'Vedaant V. Jain'},\n",
       "   {'authorId': '2275571568', 'name': 'Gagandeep Singh'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '6667d828fb87709551c14da0fab985a237ba2505',\n",
       "  'title': 'Decoding Intelligence: A Framework for Certifying Knowledge Comprehension in LLMs',\n",
       "  'url': 'https://www.semanticscholar.org/paper/6667d828fb87709551c14da0fab985a237ba2505',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.14310',\n",
       "  'authors': [{'authorId': '2243662006', 'name': 'Jinlan Fu'},\n",
       "   {'authorId': '2284985640', 'name': 'Shenzhen Huangfu'},\n",
       "   {'authorId': '146948229', 'name': 'Hang Yan'},\n",
       "   {'authorId': '2242887615', 'name': 'See-Kiong Ng'},\n",
       "   {'authorId': '2256661980', 'name': 'Xipeng Qiu'}],\n",
       "  'doi': '10.48550/arXiv.2402.14310',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'bb991838e419a3cdd8617bb6384a95f0360113a4',\n",
       "  'title': 'Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge',\n",
       "  'url': 'https://www.semanticscholar.org/paper/bb991838e419a3cdd8617bb6384a95f0360113a4',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.12185',\n",
       "  'authors': [{'authorId': '2239108883', 'name': 'Renqiu Xia'},\n",
       "   {'authorId': '2141897317', 'name': 'Bo Zhang'},\n",
       "   {'authorId': '2284665448', 'name': 'Hancheng Ye'},\n",
       "   {'authorId': '2152613980', 'name': 'Xiangchao Yan'},\n",
       "   {'authorId': '2284732510', 'name': 'Qi Liu'},\n",
       "   {'authorId': '2283347627', 'name': 'Hongbin Zhou'},\n",
       "   {'authorId': '2282981042', 'name': 'Zijun Chen'},\n",
       "   {'authorId': '2197075911', 'name': 'Min Dou'},\n",
       "   {'authorId': '119700639', 'name': 'Botian Shi'},\n",
       "   {'authorId': '2281908785', 'name': 'Junchi Yan'},\n",
       "   {'authorId': '2268766970', 'name': 'Yu Qiao'}],\n",
       "  'doi': '10.48550/arXiv.2402.12185',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '9ab82096689de59b108a0bf2667ab12cac2f8271',\n",
       "  'title': 'ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/9ab82096689de59b108a0bf2667ab12cac2f8271',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.09047',\n",
       "  'authors': [{'authorId': '2262403157', 'name': 'Yiming He'},\n",
       "   {'authorId': '2263398114', 'name': 'Jia Zou'},\n",
       "   {'authorId': '2262275741', 'name': 'Xiaokai Zhang'},\n",
       "   {'authorId': '2262218041', 'name': 'Na Zhu'},\n",
       "   {'authorId': '2259980083', 'name': 'Tuo Leng'}],\n",
       "  'doi': '10.48550/arXiv.2402.09047',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b39717e6d9b8b24b8d4dc049c5b38e49b3cd7752',\n",
       "  'title': 'FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b39717e6d9b8b24b8d4dc049c5b38e49b3cd7752',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.08147',\n",
       "  'authors': [{'authorId': '35402876', 'name': 'David Brandfonbrener'},\n",
       "   {'authorId': '2283934330', 'name': 'Sibi Raja'},\n",
       "   {'authorId': '2283931965', 'name': 'Tarun Prasad'},\n",
       "   {'authorId': '2283934175', 'name': 'Chloe Loughridge'},\n",
       "   {'authorId': '2284025023', 'name': 'Jianang Yang'},\n",
       "   {'authorId': '2222806308', 'name': 'Simon Henniger'},\n",
       "   {'authorId': '2254398988', 'name': 'William E. Byrd'},\n",
       "   {'authorId': '2237231099', 'name': 'Robert Zinkov'},\n",
       "   {'authorId': '2256397856', 'name': 'Nada Amin'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'e8e0fb257c242fabca05f6f5f31a139f2b94b8d0',\n",
       "  'title': 'VerMCTS: Synthesizing Multi-Step Programs using a Verifier, a Large Language Model, and Tree Search',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e8e0fb257c242fabca05f6f5f31a139f2b94b8d0',\n",
       "  'venue': '',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.16878',\n",
       "  'authors': [{'authorId': '2287830838', 'name': 'Johnathan Mercer'}],\n",
       "  'doi': '10.48550/arXiv.2402.16878',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4b1281324176bb09fa6140edab525d39379231ed',\n",
       "  'title': 'EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages',\n",
       "  'url': 'https://www.semanticscholar.org/paper/4b1281324176bb09fa6140edab525d39379231ed',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.06332',\n",
       "  'authors': [{'authorId': '2283772353', 'name': 'Huaiyuan Ying'},\n",
       "   {'authorId': '2257086624', 'name': 'Shuo Zhang'},\n",
       "   {'authorId': '2107897400', 'name': 'Linyang Li'},\n",
       "   {'authorId': '2157944555', 'name': 'Zhejian Zhou'},\n",
       "   {'authorId': '95329799', 'name': 'Yunfan Shao'},\n",
       "   {'authorId': '2132200788', 'name': 'Zhaoye Fei'},\n",
       "   {'authorId': '2283837879', 'name': 'Yichuan Ma'},\n",
       "   {'authorId': '2269567728', 'name': 'Jiawei Hong'},\n",
       "   {'authorId': '2029335061', 'name': 'Kuikun Liu'},\n",
       "   {'authorId': '2283815372', 'name': 'Ziyi Wang'},\n",
       "   {'authorId': '2283817440', 'name': 'Yudong Wang'},\n",
       "   {'authorId': '2283840256', 'name': 'Zijian Wu'},\n",
       "   {'authorId': '2283938826', 'name': 'Shuaibin Li'},\n",
       "   {'authorId': '2248972766', 'name': 'Fengzhe Zhou'},\n",
       "   {'authorId': '2261249592', 'name': 'Hongwei Liu'},\n",
       "   {'authorId': '2266356137', 'name': 'Songyang Zhang'},\n",
       "   {'authorId': '2266359401', 'name': 'Wenwei Zhang'},\n",
       "   {'authorId': '13730519', 'name': 'Hang Yan'},\n",
       "   {'authorId': '2256661980', 'name': 'Xipeng Qiu'},\n",
       "   {'authorId': '2283823680', 'name': 'Jiayu Wang'},\n",
       "   {'authorId': '2275790072', 'name': 'Kai Chen'},\n",
       "   {'authorId': '2261095726', 'name': 'Dahua Lin'}],\n",
       "  'doi': '10.48550/arXiv.2402.06332',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'af1d4a4141eaf52384ca85f1d468443f8f3d5c06',\n",
       "  'title': 'InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning',\n",
       "  'url': 'https://www.semanticscholar.org/paper/af1d4a4141eaf52384ca85f1d468443f8f3d5c06',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.03268',\n",
       "  'authors': [{'authorId': '2115553132', 'name': 'Xinyi Wang'},\n",
       "   {'authorId': '2039956094', 'name': 'Alfonso Amayuelas'},\n",
       "   {'authorId': '2119058805', 'name': 'Kexun Zhang'},\n",
       "   {'authorId': '2256983134', 'name': 'Liangming Pan'},\n",
       "   {'authorId': '2109664620', 'name': 'Wenhu Chen'},\n",
       "   {'authorId': '2257130314', 'name': 'W. Wang'}],\n",
       "  'doi': '10.48550/arXiv.2402.03268',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f76b280d9201cf0ae43717afe05ce15edeb13bb1',\n",
       "  'title': 'Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f76b280d9201cf0ae43717afe05ce15edeb13bb1',\n",
       "  'venue': 'ICML',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.02104',\n",
       "  'authors': [{'authorId': '134254282', 'name': 'Konstantinos Kogkalidis'},\n",
       "   {'authorId': '73777281', 'name': 'Orestis Melkonian'},\n",
       "   {'authorId': '144701616', 'name': 'Jean-Philippe Bernardy'}],\n",
       "  'doi': '10.48550/arXiv.2402.02104',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f2285146fd02caefbfa9180217f1c7162246ea9e',\n",
       "  'title': 'Learning Structure-Aware Representations of Dependent Types',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f2285146fd02caefbfa9180217f1c7162246ea9e',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2402.01717',\n",
       "  'authors': [{'authorId': '2282545265', 'name': 'Jaewoong Kim'},\n",
       "   {'authorId': '2282539913', 'name': 'Moohong Min'}],\n",
       "  'doi': '10.48550/arXiv.2402.01717',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '2eff8cbb4b226575a2f6aa93c40804c163e463ac',\n",
       "  'title': 'From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process',\n",
       "  'url': 'https://www.semanticscholar.org/paper/2eff8cbb4b226575a2f6aa93c40804c163e463ac',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2401.07663',\n",
       "  'authors': [{'authorId': '2279656980', 'name': 'Lichen Zhang'},\n",
       "   {'authorId': '2274063415', 'name': 'Shuai Lu'},\n",
       "   {'authorId': '2273685555', 'name': 'Nan Duan'}],\n",
       "  'doi': '10.48550/arXiv.2401.07663',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '43df67f91c2428121b6392d751c4e65fde5c8a97',\n",
       "  'title': 'Selene: Pioneering Automated Proof in Software Verification',\n",
       "  'url': 'https://www.semanticscholar.org/paper/43df67f91c2428121b6392d751c4e65fde5c8a97',\n",
       "  'venue': 'ACL',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2401.02949',\n",
       "  'authors': [{'authorId': '1585458992', 'name': 'Lasse Blaauwbroek'},\n",
       "   {'authorId': '2280337970', 'name': 'Miroslav Olšák'},\n",
       "   {'authorId': '2278218634', 'name': 'Jason Rute'},\n",
       "   {'authorId': '48398315', 'name': 'F. I. S. Massolo'},\n",
       "   {'authorId': '2048060685', 'name': 'Jelle Piepenbrock'},\n",
       "   {'authorId': '2278217260', 'name': 'Vasily Pestun'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '955420033e82248e16344a256b39e4030aea2da6',\n",
       "  'title': 'Graph2Tac: Online Representation Learning of Formal Math Concepts',\n",
       "  'url': 'https://www.semanticscholar.org/paper/955420033e82248e16344a256b39e4030aea2da6',\n",
       "  'venue': 'ICML',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2401.02950',\n",
       "  'authors': [{'authorId': '1585458992', 'name': 'Lasse Blaauwbroek'}],\n",
       "  'doi': '10.48550/arXiv.2401.02950',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4dd6102d63fb21631a0514d5a693531d48eebaaa',\n",
       "  'title': \"The Tactician's Web of Large-Scale Formal Knowledge\",\n",
       "  'url': 'https://www.semanticscholar.org/paper/4dd6102d63fb21631a0514d5a693531d48eebaaa',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2401.00963',\n",
       "  'authors': [{'authorId': '2279547215', 'name': 'Álvaro Silva'},\n",
       "   {'authorId': '33974891', 'name': 'A. Mendes'},\n",
       "   {'authorId': '2260093437', 'name': 'João F. Ferreira'}],\n",
       "  'doi': '10.1145/3644033.3644374',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'e26ae4db16142a64daf67768f8064321d6f13945',\n",
       "  'title': 'Leveraging Large Language Models to Boost Dafny’s Developers Productivity',\n",
       "  'url': 'https://www.semanticscholar.org/paper/e26ae4db16142a64daf67768f8064321d6f13945',\n",
       "  'venue': '2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE)',\n",
       "  'year': 2024},\n",
       " {'arxivId': '2401.08664',\n",
       "  'authors': [{'authorId': '2260837684', 'name': 'Qingyao Li'},\n",
       "   {'authorId': '2171109846', 'name': 'Lingyue Fu'},\n",
       "   {'authorId': '2237819504', 'name': 'Weiming Zhang'},\n",
       "   {'authorId': '150343399', 'name': 'Xianyu Chen'},\n",
       "   {'authorId': '2276822936', 'name': 'Jingwei Yu'},\n",
       "   {'authorId': '2154454480', 'name': 'Wei Xia'},\n",
       "   {'authorId': '2240768092', 'name': 'Weinan Zhang'},\n",
       "   {'authorId': '2257180930', 'name': 'Ruiming Tang'},\n",
       "   {'authorId': '2237958078', 'name': 'Yong Yu'}],\n",
       "  'doi': '10.48550/arXiv.2401.08664',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'fee61c03fd5ad4a8d8bcdec5bcdfacfe25b361d9',\n",
       "  'title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges',\n",
       "  'url': 'https://www.semanticscholar.org/paper/fee61c03fd5ad4a8d8bcdec5bcdfacfe25b361d9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2312.14188',\n",
       "  'authors': [{'authorId': '2273363058', 'name': 'Rahul Vishwakarma'},\n",
       "   {'authorId': '2242413862', 'name': 'Subhankar Mishra'}],\n",
       "  'doi': '10.48550/arXiv.2312.14188',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '0eef63fe71efba4404a9a883bf89ec634dbaad82',\n",
       "  'title': 'Enhancing Neural Theorem Proving through Data Augmentation and Dynamic Sampling Method',\n",
       "  'url': 'https://www.semanticscholar.org/paper/0eef63fe71efba4404a9a883bf89ec634dbaad82',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2312.08926',\n",
       "  'authors': [{'authorId': '2273328586', 'name': 'Haoran Liao'},\n",
       "   {'authorId': '2129991600', 'name': 'Qinyi Du'},\n",
       "   {'authorId': '2274562434', 'name': 'Shaohua Hu'},\n",
       "   {'authorId': '100537432', 'name': 'Hao He'},\n",
       "   {'authorId': '2260419917', 'name': 'Yanyan Xu'},\n",
       "   {'authorId': '2136089851', 'name': 'Jidong Tian'},\n",
       "   {'authorId': '2257387631', 'name': 'Yaohui Jin'}],\n",
       "  'doi': '10.48550/arXiv.2312.08926',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '7017c58e19f4db0c38040935cc9fb7b7090a466d',\n",
       "  'title': 'Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent',\n",
       "  'url': 'https://www.semanticscholar.org/paper/7017c58e19f4db0c38040935cc9fb7b7090a466d',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2312.04556',\n",
       "  'authors': [{'authorId': '2127069744', 'name': 'Simon Frieder'},\n",
       "   {'authorId': '2270678022', 'name': 'Julius Berner'},\n",
       "   {'authorId': '2203427985', 'name': 'Philipp Petersen'},\n",
       "   {'authorId': '2250244942', 'name': 'Thomas Lukasiewicz'}],\n",
       "  'doi': '10.48550/arXiv.2312.04556',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a987c21afbfb3bd746d114e248202c074b1c40ca',\n",
       "  'title': 'Large Language Models for Mathematicians',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a987c21afbfb3bd746d114e248202c074b1c40ca',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2312.03042',\n",
       "  'authors': [{'authorId': '2269960967', 'name': 'He Yan'},\n",
       "   {'authorId': '2271499445', 'name': 'Xinyao Hu'},\n",
       "   {'authorId': '2270046241', 'name': 'Xiangpeng Wan'},\n",
       "   {'authorId': '2270744256', 'name': 'Chengyu Huang'},\n",
       "   {'authorId': '2270377502', 'name': 'Kai Zou'},\n",
       "   {'authorId': '2269851948', 'name': 'Shiqi Xu'}],\n",
       "  'doi': '10.48550/arXiv.2312.03042',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '9d7945c07643fe7f96e2389c8b39846eafdcacb5',\n",
       "  'title': 'Inherent limitations of LLMs regarding spatial information',\n",
       "  'url': 'https://www.semanticscholar.org/paper/9d7945c07643fe7f96e2389c8b39846eafdcacb5',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2311.11482',\n",
       "  'authors': [{'authorId': '2281903182', 'name': 'Yifan Zhang'},\n",
       "   {'authorId': '2294673772', 'name': 'Yang Yuan'},\n",
       "   {'authorId': '2279754345', 'name': 'Andrew Chi-Chih Yao'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f502cf5c371f3768362816e2fefca1e8d2751341',\n",
       "  'title': 'Meta Prompting for AI Systems',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f502cf5c371f3768362816e2fefca1e8d2751341',\n",
       "  'venue': '',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2311.03645',\n",
       "  'authors': [{'authorId': '2265581407', 'name': 'Bernardo Subercaseaux'},\n",
       "   {'authorId': '2265580933', 'name': 'John Mackey'},\n",
       "   {'authorId': '2265542772', 'name': 'Marijn Heule'},\n",
       "   {'authorId': '2265581596', 'name': 'Ruben Martins'}],\n",
       "  'doi': '10.1007/978-3-031-66997-2_2',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '04aeed5d83b2b25ef829a7a6cfe9cccc4c1a9e86',\n",
       "  'title': 'Automated Mathematical Discovery and Verification: Minimizing Pentagons in the Plane',\n",
       "  'url': 'https://www.semanticscholar.org/paper/04aeed5d83b2b25ef829a7a6cfe9cccc4c1a9e86',\n",
       "  'venue': 'CICM',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2311.03755',\n",
       "  'authors': [{'authorId': '2063969818', 'name': 'Albert Qiaochu Jiang'},\n",
       "   {'authorId': '2265619289', 'name': 'Wenda Li'},\n",
       "   {'authorId': '1708741', 'name': 'M. Jamnik'}],\n",
       "  'doi': '10.48550/arXiv.2311.03755',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'baa727294fd380959118abae5e7a985e4975f857',\n",
       "  'title': 'Multilingual Mathematical Autoformalization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/baa727294fd380959118abae5e7a985e4975f857',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.18457',\n",
       "  'authors': [{'authorId': '2129663', 'name': 'S. Welleck'},\n",
       "   {'authorId': '2262443949', 'name': 'Rahul Saha'}],\n",
       "  'doi': '10.48550/arXiv.2310.18457',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '96a9546fdb2f147ced3a03d4c98b6c900ecd1b8c',\n",
       "  'title': 'LLMSTEP: LLM proofstep suggestions in Lean',\n",
       "  'url': 'https://www.semanticscholar.org/paper/96a9546fdb2f147ced3a03d4c98b6c900ecd1b8c',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.10631',\n",
       "  'authors': [{'authorId': '2124977416', 'name': 'Zhangir Azerbayev'},\n",
       "   {'authorId': '2184031883', 'name': 'Hailey Schoelkopf'},\n",
       "   {'authorId': '73775191', 'name': 'Keiran Paster'},\n",
       "   {'authorId': '2257332063', 'name': 'Marco Dos Santos'},\n",
       "   {'authorId': '2258957756', 'name': 'S. McAleer'},\n",
       "   {'authorId': '2278435713', 'name': 'Albert Q. Jiang'},\n",
       "   {'authorId': '2260297681', 'name': 'Jia Deng'},\n",
       "   {'authorId': '103476203', 'name': 'Stella Biderman'},\n",
       "   {'authorId': '2129663', 'name': 'S. Welleck'}],\n",
       "  'doi': '10.48550/arXiv.2310.10631',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b16c7d45183b9d595ab64301be019741b1528860',\n",
       "  'title': 'Llemma: An Open Language Model For Mathematics',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b16c7d45183b9d595ab64301be019741b1528860',\n",
       "  'venue': 'ICLR',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.10180',\n",
       "  'authors': [{'authorId': '2175277130', 'name': 'Jing Xiong'},\n",
       "   {'authorId': '2115733983', 'name': 'Jianhao Shen'},\n",
       "   {'authorId': '2221302624', 'name': 'Ye Yuan'},\n",
       "   {'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '1384668226', 'name': 'Yichun Yin'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2251528531', 'name': 'Lin Li'},\n",
       "   {'authorId': '2681038', 'name': 'Zhijiang Guo'},\n",
       "   {'authorId': '2249759360', 'name': 'Qingxing Cao'},\n",
       "   {'authorId': '153268218', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2238892973', 'name': 'Chuanyang Zheng'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'},\n",
       "   {'authorId': '2145178175', 'name': 'Ming Zhang'},\n",
       "   {'authorId': '2238911873', 'name': 'Qun Liu'}],\n",
       "  'doi': '10.48550/arXiv.2310.10180',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a419e1d74cfc2b5ff400963476bda5c6ae66e172',\n",
       "  'title': 'TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a419e1d74cfc2b5ff400963476bda5c6ae66e172',\n",
       "  'venue': 'EMNLP',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.10080',\n",
       "  'authors': [{'authorId': '2258790160', 'name': 'Qianli Ma'},\n",
       "   {'authorId': '2258876454', 'name': 'Haotian Zhou'},\n",
       "   {'authorId': '2254792618', 'name': 'Tingkai Liu'},\n",
       "   {'authorId': '2257015367', 'name': 'Jianbo Yuan'},\n",
       "   {'authorId': '2258936203', 'name': 'Pengfei Liu'},\n",
       "   {'authorId': '2258772720', 'name': 'Yang You'},\n",
       "   {'authorId': '2212243155', 'name': 'Hongxia Yang'}],\n",
       "  'doi': '10.48550/arXiv.2310.10080',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '44b506d9619b5f957dc2b5588801138f343c0308',\n",
       "  'title': \"Let's reward step by step: Step-Level reward model as the Navigators for Reasoning\",\n",
       "  'url': 'https://www.semanticscholar.org/paper/44b506d9619b5f957dc2b5588801138f343c0308',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.07957',\n",
       "  'authors': [{'authorId': '2258336135', 'name': 'Nilay Patel'},\n",
       "   {'authorId': '2257344888', 'name': 'Rahul Saha'},\n",
       "   {'authorId': '2273066958', 'name': 'Jeffrey Flanigan'}],\n",
       "  'doi': '10.48550/arXiv.2310.07957',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'fef1919d3a55652004fd012e052fe5b8f726f4e9',\n",
       "  'title': 'A New Approach Towards Autoformalization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/fef1919d3a55652004fd012e052fe5b8f726f4e9',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.05707',\n",
       "  'authors': [{'authorId': '2309866809', 'name': 'Xinyi Wang'},\n",
       "   {'authorId': '51889580', 'name': 'Lucas Caccia'},\n",
       "   {'authorId': '145191120', 'name': 'O. Ostapenko'},\n",
       "   {'authorId': '2258299929', 'name': 'Xingdi Yuan'},\n",
       "   {'authorId': '2041695', 'name': 'Alessandro Sordoni'}],\n",
       "  'doi': '10.48550/arXiv.2310.05707',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b29134737a0c81c13d31fc0263b3c4d4f05ccb78',\n",
       "  'title': 'Guiding Language Model Reasoning with Planning Tokens',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b29134737a0c81c13d31fc0263b3c4d4f05ccb78',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.04353',\n",
       "  'authors': [{'authorId': '2070335783', 'name': 'Amitayush Thakur'},\n",
       "   {'authorId': '2072570293', 'name': 'G. Tsoukalas'},\n",
       "   {'authorId': '2258435378', 'name': 'Yeming Wen'},\n",
       "   {'authorId': '2283305806', 'name': 'Jimmy Xin'},\n",
       "   {'authorId': '2248225759', 'name': 'Swarat Chaudhuri'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'ee71447d68f3d8666c974b8199e330e19aebf263',\n",
       "  'title': 'An In-Context Learning Agent for Formal Theorem-Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/ee71447d68f3d8666c974b8199e330e19aebf263',\n",
       "  'venue': '',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.03184',\n",
       "  'authors': [{'authorId': '51915733', 'name': 'Zachary Levonian'},\n",
       "   {'authorId': '2255366203', 'name': 'Chenglu Li'},\n",
       "   {'authorId': '2238720345', 'name': 'Wangda Zhu'},\n",
       "   {'authorId': '2254272960', 'name': 'Anoushka Gade'},\n",
       "   {'authorId': '2254260121', 'name': 'Owen Henkel'},\n",
       "   {'authorId': '2254269074', 'name': 'Millie-Ellen Postle'},\n",
       "   {'authorId': '2257373730', 'name': 'Wanli Xing'}],\n",
       "  'doi': '10.48550/arXiv.2310.03184',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '3dc1b657bf821b731c5ed0396823b67c10d54ba1',\n",
       "  'title': 'Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference',\n",
       "  'url': 'https://www.semanticscholar.org/paper/3dc1b657bf821b731c5ed0396823b67c10d54ba1',\n",
       "  'venue': 'EDM',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2310.00656',\n",
       "  'authors': [{'authorId': '2238628841', 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '2238892973', 'name': 'Chuanyang Zheng'},\n",
       "   {'authorId': '2251528531', 'name': 'Lin Li'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2249759360', 'name': 'Qingxing Cao'},\n",
       "   {'authorId': '153268218', 'name': 'Yinya Huang'},\n",
       "   {'authorId': '2175277130', 'name': 'Jing Xiong'},\n",
       "   {'authorId': '152751416', 'name': 'Han Shi'},\n",
       "   {'authorId': '2247612880', 'name': 'Enze Xie'},\n",
       "   {'authorId': '2249872910', 'name': 'Jian Yin'},\n",
       "   {'authorId': '2249755860', 'name': 'Zhenguo Li'},\n",
       "   {'authorId': '2252982591', 'name': 'Xiaodan Liang'},\n",
       "   {'authorId': '2310414238', 'name': 'Heng Liao'}],\n",
       "  'doi': '10.48550/arXiv.2310.00656',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f8b5ee53c3410f20049e7def47bd52403fa388e3',\n",
       "  'title': 'LEGO-Prover: Neural Theorem Proving with Growing Libraries',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f8b5ee53c3410f20049e7def47bd52403fa388e3',\n",
       "  'venue': 'ICLR',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2309.15806',\n",
       "  'authors': [{'authorId': '2238892973', 'name': 'Chuanyang Zheng'},\n",
       "   {'authorId': '2109589929', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '2247612880', 'name': 'Enze Xie'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2247730541', 'name': 'Jiankai Sun'},\n",
       "   {'authorId': '2238628841', 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2115733983', 'name': 'Jianhao Shen'},\n",
       "   {'authorId': '121544682', 'name': 'Zheng Li'},\n",
       "   {'authorId': '2249753981', 'name': 'Yu Li'}],\n",
       "  'doi': '10.48550/arXiv.2309.15806',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'd4b542847e1dd227e90479f4b3523a81dee33b7a',\n",
       "  'title': 'Lyra: Orchestrating Dual Correction in Automated Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/d4b542847e1dd227e90479f4b3523a81dee33b7a',\n",
       "  'venue': 'Trans. Mach. Learn. Res.',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2309.10691',\n",
       "  'authors': [{'authorId': '2144803999', 'name': 'Xingyao Wang'},\n",
       "   {'authorId': '2243360876', 'name': 'Zihan Wang'},\n",
       "   {'authorId': '33456794', 'name': 'Jiateng Liu'},\n",
       "   {'authorId': '123331686', 'name': 'Yangyi Chen'},\n",
       "   {'authorId': '2152195191', 'name': 'Lifan Yuan'},\n",
       "   {'authorId': '1818378366', 'name': 'Hao Peng'},\n",
       "   {'authorId': '2243197103', 'name': 'Heng Ji'}],\n",
       "  'doi': '10.48550/arXiv.2309.10691',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '12b233752c7097ea6525622bed238ae2d2193c5a',\n",
       "  'title': 'MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback',\n",
       "  'url': 'https://www.semanticscholar.org/paper/12b233752c7097ea6525622bed238ae2d2193c5a',\n",
       "  'venue': 'ICLR',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2309.09435',\n",
       "  'authors': [{'authorId': '2257009045', 'name': 'Tao Wang'},\n",
       "   {'authorId': '2108051942', 'name': 'Yushu Zhang'},\n",
       "   {'authorId': '153068904', 'name': 'Shuren Qi'},\n",
       "   {'authorId': '2090460634', 'name': 'Ruoyu Zhao'},\n",
       "   {'authorId': '2242924922', 'name': 'Zhihua Xia'},\n",
       "   {'authorId': '2243062439', 'name': 'Jian Weng'}],\n",
       "  'doi': '10.48550/arXiv.2309.09435',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'a11c695b34bb7f5cc8e6e96d8e6e037229394514',\n",
       "  'title': 'Security and Privacy on Generative Data in AIGC: A Survey',\n",
       "  'url': 'https://www.semanticscholar.org/paper/a11c695b34bb7f5cc8e6e96d8e6e037229394514',\n",
       "  'venue': 'ACM Computing Surveys',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2308.10410',\n",
       "  'authors': [{'authorId': '2232906828', 'name': 'Fan Gao'},\n",
       "   {'authorId': '48579520', 'name': 'Hang Jiang'},\n",
       "   {'authorId': '2287835229', 'name': 'Rui Yang'},\n",
       "   {'authorId': '2153554138', 'name': 'Qingcheng Zeng'},\n",
       "   {'authorId': '2285824559', 'name': 'Jinghui Lu'},\n",
       "   {'authorId': '2285108151', 'name': 'Moritz Blum'},\n",
       "   {'authorId': '1585849884', 'name': 'Dairui Liu'},\n",
       "   {'authorId': '2106009217', 'name': 'Tianwei She'},\n",
       "   {'authorId': '2285289624', 'name': 'Yuang Jiang'},\n",
       "   {'authorId': '2275053812', 'name': 'Irene Li'}],\n",
       "  'doi': '10.18653/v1/2024.findings-acl.321',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'b56ce5cea6963f5684124caa03df470f4144d895',\n",
       "  'title': 'Evaluating Large Language Models on Wikipedia-Style Survey Generation',\n",
       "  'url': 'https://www.semanticscholar.org/paper/b56ce5cea6963f5684124caa03df470f4144d895',\n",
       "  'venue': 'ACL',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2308.04371',\n",
       "  'authors': [{'authorId': '2108464109', 'name': 'Yifan Zhang'},\n",
       "   {'authorId': '2121269197', 'name': 'Jingqin Yang'},\n",
       "   {'authorId': '2116944866', 'name': 'Yang Yuan'},\n",
       "   {'authorId': '1770729', 'name': 'A. Yao'}],\n",
       "  'doi': '10.48550/arXiv.2308.04371',\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '507acddb0b7f36b83fd7c8bff2f121eb506ac8fb',\n",
       "  'title': 'Cumulative Reasoning with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/507acddb0b7f36b83fd7c8bff2f121eb506ac8fb',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2307.06435',\n",
       "  'authors': [{'authorId': '32749940', 'name': 'Humza Naveed'},\n",
       "   {'authorId': '2201619569', 'name': 'Asad Ullah Khan'},\n",
       "   {'authorId': '2055117257', 'name': 'Shi Qiu'},\n",
       "   {'authorId': '2153464760', 'name': 'Muhammad Saqib'},\n",
       "   {'authorId': '49053414', 'name': 'Saeed Anwar'},\n",
       "   {'authorId': '2223436301', 'name': 'Muhammad Usman'},\n",
       "   {'authorId': '1712576', 'name': 'Nick Barnes'},\n",
       "   {'authorId': '1747500', 'name': 'A. Mian'}],\n",
       "  'doi': '10.48550/arXiv.2307.06435',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'ca31b8584b6c022ef15ddfe994fe361e002b7729',\n",
       "  'title': 'A Comprehensive Overview of Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/ca31b8584b6c022ef15ddfe994fe361e002b7729',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2307.02502',\n",
       "  'authors': [{'authorId': '46838780', 'name': 'M. Swan'},\n",
       "   {'authorId': '2062583457', 'name': 'Takashi Kido'},\n",
       "   {'authorId': '2221202554', 'name': 'Eric Roland'},\n",
       "   {'authorId': '143749184', 'name': 'R. P. D. Santos'}],\n",
       "  'doi': '10.48550/arXiv.2307.02502',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '90fff3e6c55fc43f81e96fea1dc63f114cc036c1',\n",
       "  'title': 'Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics',\n",
       "  'url': 'https://www.semanticscholar.org/paper/90fff3e6c55fc43f81e96fea1dc63f114cc036c1',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2303.04488',\n",
       "  'authors': [{'authorId': '2060045325', 'name': 'Maciej Mikuła'},\n",
       "   {'authorId': '2184103686', 'name': 'Szymon Antoniak'},\n",
       "   {'authorId': '2134879789', 'name': 'Szymon Tworkowski'},\n",
       "   {'authorId': '2063969818', 'name': 'Albert Qiaochu Jiang'},\n",
       "   {'authorId': '2045752667', 'name': 'Jinyi Zhou'},\n",
       "   {'authorId': '2574060', 'name': 'Christian Szegedy'},\n",
       "   {'authorId': '2167581543', 'name': \"Lukasz Kuci'nski\"},\n",
       "   {'authorId': '2166052432', 'name': \"Piotr Milo's\"},\n",
       "   {'authorId': '3374063', 'name': 'Yuhuai Wu'}],\n",
       "  'doi': '10.48550/arXiv.2303.04488',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': True,\n",
       "  'paperId': 'f661bdc053ba13df80eda479791306e1178db235',\n",
       "  'title': 'Magnushammer: A Transformer-based Approach to Premise Selection',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f661bdc053ba13df80eda479791306e1178db235',\n",
       "  'venue': 'ICLR',\n",
       "  'year': 2023},\n",
       " {'arxivId': '2210.12150',\n",
       "  'authors': [{'authorId': '2188654050', 'name': 'Maxwell P. Bobbin'},\n",
       "   {'authorId': '2188653934', 'name': 'Samiha Sharlin'},\n",
       "   {'authorId': '2188653929', 'name': 'Parivash Feyzishendi'},\n",
       "   {'authorId': '1412702182', 'name': 'Andrey Dang'},\n",
       "   {'authorId': '2188654221', 'name': 'Catherine M. Wraback'},\n",
       "   {'authorId': '39447417', 'name': 'Tyler R. Josephson'}],\n",
       "  'doi': '10.1039/d3dd00077j',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '021ca8adbfbe78b838f2aed05a0b42acf6e45510',\n",
       "  'title': 'Formalizing Chemical Physics using the Lean Theorem Prover',\n",
       "  'url': 'https://www.semanticscholar.org/paper/021ca8adbfbe78b838f2aed05a0b42acf6e45510',\n",
       "  'venue': 'Digital Discovery',\n",
       "  'year': 2022},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2278218634', 'name': 'Jason Rute'},\n",
       "   {'authorId': '2280337970', 'name': 'Miroslav Olšák'},\n",
       "   {'authorId': '1585458992', 'name': 'Lasse Blaauwbroek'},\n",
       "   {'authorId': '48398315', 'name': 'F. I. S. Massolo'},\n",
       "   {'authorId': '2048060685', 'name': 'Jelle Piepenbrock'},\n",
       "   {'authorId': '2278217260', 'name': 'Vasily Pestun'}],\n",
       "  'doi': '10.48550/arXiv.2401.02949',\n",
       "  'intent': ['background', 'methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'af451aa3ba4138d789d5276b874d2167aa525bbd',\n",
       "  'title': 'Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/af451aa3ba4138d789d5276b874d2167aa525bbd',\n",
       "  'venue': 'ArXiv',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2316808539', 'name': 'Chenghua Huang'},\n",
       "   {'authorId': '2244180854', 'name': 'Shisong Chen'},\n",
       "   {'authorId': '2243457917', 'name': 'Zhixu Li'},\n",
       "   {'authorId': '2069479032', 'name': 'Jianfeng Qu'},\n",
       "   {'authorId': '2265724350', 'name': 'Yanghua Xiao'},\n",
       "   {'authorId': '2307566767', 'name': 'Jiaxin Liu'},\n",
       "   {'authorId': '2316780968', 'name': 'Zhigang Chen'}],\n",
       "  'doi': '10.18653/v1/2024.findings-acl.362',\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '64cdeb71b3896cc4b6abf9107402504166c1b2c0',\n",
       "  'title': 'GeoAgent: To Empower LLMs using Geospatial Tools for Address Standardization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/64cdeb71b3896cc4b6abf9107402504166c1b2c0',\n",
       "  'venue': 'ACL',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2329739232', 'name': 'Vanessa Lama'},\n",
       "   {'authorId': '2329752938', 'name': 'Catherine Ma'},\n",
       "   {'authorId': '2301583035', 'name': 'Tirthankar Ghosal'}],\n",
       "  'doi': '10.18653/v1/2024.nlp4science-1.18',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '696ec3063c3600d7c8ef53e6d52adb037c5da73a',\n",
       "  'title': 'Benchmarking Automated Theorem Proving with Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/696ec3063c3600d7c8ef53e6d52adb037c5da73a',\n",
       "  'venue': 'NLP4SCIENCE',\n",
       "  'year': 2024},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2238892973', 'name': 'Chuanyang Zheng'},\n",
       "   {'authorId': '2249840940', 'name': 'Haiming Wang'},\n",
       "   {'authorId': '2247612880', 'name': 'Enze Xie'},\n",
       "   {'authorId': '2239065052', 'name': 'Zhengying Liu'},\n",
       "   {'authorId': '2247730541', 'name': 'Jiankai Sun'},\n",
       "   {'authorId': None, 'name': 'Huajian Xin'},\n",
       "   {'authorId': '2316957573', 'name': 'Jianhao Shen'},\n",
       "   {'authorId': '2253395155', 'name': 'Zhenguo Li'},\n",
       "   {'authorId': '2249753981', 'name': 'Yu Li'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '7ec4416f4017bb7c76df9b9ff313021bb2dca3ec',\n",
       "  'title': 'L YRA : O RCHESTRATING D UAL C ORRECTION IN A UTO - MATED T HEOREM P ROVING',\n",
       "  'url': 'https://www.semanticscholar.org/paper/7ec4416f4017bb7c76df9b9ff313021bb2dca3ec',\n",
       "  'venue': '',\n",
       "  'year': 2023},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2308031392', 'name': 'Moa Johansson'}],\n",
       "  'doi': '10.1007/978-3-031-46002-9_25',\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '62fd472261535436d058c48e2489614fc272b6d7',\n",
       "  'title': 'What Can Large Language Models Do for Theorem Proving and Formal Methods?',\n",
       "  'url': 'https://www.semanticscholar.org/paper/62fd472261535436d058c48e2489614fc272b6d7',\n",
       "  'venue': 'AISoLA',\n",
       "  'year': 2023},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2233293602', 'name': 'Fabian Gloeckle'},\n",
       "   {'authorId': '2282469774', 'name': 'Gabriele Synnaeve'},\n",
       "   {'authorId': '2046132510', 'name': 'Amaury Hayat'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': True,\n",
       "  'paperId': '2865fd772fd5d14eabe20cdea20d057c36570ef8',\n",
       "  'title': 'ABEL: Sample Efficient Online Reinforcement Learning for Neural Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/2865fd772fd5d14eabe20cdea20d057c36570ef8',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2292955145', 'name': 'Nuraini Sulaiman'},\n",
       "   {'authorId': '2292955221', 'name': 'Farizal Hamzah'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '529b911da40fa9df598cfbb589e84af5b7c18f0d',\n",
       "  'title': 'Evaluation of Transfer Learning and Adaptability in Large Language Models with the GLUE Benchmark',\n",
       "  'url': 'https://www.semanticscholar.org/paper/529b911da40fa9df598cfbb589e84af5b7c18f0d',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2294786109', 'name': 'Xijia Tao'}],\n",
       "  'doi': None,\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '4719a2cdb847b9299190cd304ed6f7e713bcd0b2',\n",
       "  'title': 'FYP Interim Report Large Language Models for Formal Theorem Proving',\n",
       "  'url': 'https://www.semanticscholar.org/paper/4719a2cdb847b9299190cd304ed6f7e713bcd0b2',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2297917081', 'name': 'Jakob Nordhagen'}],\n",
       "  'doi': None,\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '0c67f2707c139d29f9f5d2ca38e80f253265ea54',\n",
       "  'title': 'Autoformalization with Backtranslation: Training an Automated Mathematician',\n",
       "  'url': 'https://www.semanticscholar.org/paper/0c67f2707c139d29f9f5d2ca38e80f253265ea54',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2299198837', 'name': 'Dr. Lingpeng Kong'}],\n",
       "  'doi': None,\n",
       "  'intent': ['background'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': 'f32464bac681376f73c76cafef60b9228e148a74',\n",
       "  'title': 'Empowering Scientific Discoveries with Artificial Intelligence: A Synergy between Formal Theorem Proving and Large Language Models',\n",
       "  'url': 'https://www.semanticscholar.org/paper/f32464bac681376f73c76cafef60b9228e148a74',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '1865800402', 'name': 'Y. Bengio'},\n",
       "   {'authorId': '2067020770', 'name': 'Nikolay Malkin'}],\n",
       "  'doi': None,\n",
       "  'intent': ['methodology'],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '58dc1ee383f62f932692c265ab2dfb997f9076d2',\n",
       "  'title': 'Edinburgh Research Explorer Machine learning and information theory concepts towards an AI mathematician',\n",
       "  'url': 'https://www.semanticscholar.org/paper/58dc1ee383f62f932692c265ab2dfb997f9076d2',\n",
       "  'venue': '',\n",
       "  'year': None},\n",
       " {'arxivId': None,\n",
       "  'authors': [{'authorId': '2063969818', 'name': 'Albert Qiaochu Jiang'},\n",
       "   {'authorId': '2265619289', 'name': 'Wenda Li'},\n",
       "   {'authorId': '1708741', 'name': 'M. Jamnik'}],\n",
       "  'doi': None,\n",
       "  'intent': [],\n",
       "  'isInfluential': False,\n",
       "  'paperId': '0751c62e0509d12c7bb1bcebf9f1268d711b0a43',\n",
       "  'title': 'Multi-language Diversity Benefits Autoformalization',\n",
       "  'url': 'https://www.semanticscholar.org/paper/0751c62e0509d12c7bb1bcebf9f1268d711b0a43',\n",
       "  'venue': '',\n",
       "  'year': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_citations_from_semantic_scholar(main_paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1, Unique ArXiv IDs found: 163\n",
      "Depth: 1, Unique ArXiv IDs found: 173\n",
      "Depth: 1, Unique ArXiv IDs found: 174\n",
      "Depth: 1, Unique ArXiv IDs found: 178\n",
      "Depth: 1, Unique ArXiv IDs found: 187\n",
      "Depth: 1, Unique ArXiv IDs found: 187\n",
      "Depth: 1, Unique ArXiv IDs found: 187\n",
      "Depth: 1, Unique ArXiv IDs found: 188\n",
      "Depth: 1, Unique ArXiv IDs found: 188\n",
      "Depth: 1, Unique ArXiv IDs found: 189\n",
      "Depth: 1, Unique ArXiv IDs found: 190\n",
      "Depth: 1, Unique ArXiv IDs found: 200\n",
      "Depth: 1, Unique ArXiv IDs found: 203\n",
      "Depth: 1, Unique ArXiv IDs found: 203\n",
      "Depth: 1, Unique ArXiv IDs found: 203\n",
      "Depth: 1, Unique ArXiv IDs found: 204\n",
      "Depth: 1, Unique ArXiv IDs found: 204\n",
      "Depth: 1, Unique ArXiv IDs found: 208\n",
      "Depth: 1, Unique ArXiv IDs found: 210\n",
      "Depth: 1, Unique ArXiv IDs found: 214\n",
      "Depth: 1, Unique ArXiv IDs found: 216\n",
      "Depth: 1, Unique ArXiv IDs found: 219\n",
      "Depth: 1, Unique ArXiv IDs found: 220\n",
      "Depth: 1, Unique ArXiv IDs found: 221\n",
      "Depth: 1, Unique ArXiv IDs found: 222\n",
      "Depth: 1, Unique ArXiv IDs found: 222\n",
      "Depth: 1, Unique ArXiv IDs found: 228\n",
      "Depth: 1, Unique ArXiv IDs found: 228\n",
      "Depth: 1, Unique ArXiv IDs found: 232\n",
      "Depth: 1, Unique ArXiv IDs found: 235\n",
      "Depth: 1, Unique ArXiv IDs found: 237\n",
      "Depth: 1, Unique ArXiv IDs found: 242\n",
      "Depth: 1, Unique ArXiv IDs found: 242\n",
      "Depth: 1, Unique ArXiv IDs found: 246\n",
      "Depth: 1, Unique ArXiv IDs found: 250\n",
      "Depth: 1, Unique ArXiv IDs found: 251\n",
      "Depth: 1, Unique ArXiv IDs found: 253\n",
      "Depth: 1, Unique ArXiv IDs found: 253\n",
      "Depth: 1, Unique ArXiv IDs found: 253\n",
      "Depth: 1, Unique ArXiv IDs found: 256\n",
      "Depth: 1, Unique ArXiv IDs found: 264\n",
      "Depth: 1, Unique ArXiv IDs found: 265\n",
      "Depth: 1, Unique ArXiv IDs found: 269\n",
      "Depth: 1, Unique ArXiv IDs found: 281\n",
      "Depth: 1, Unique ArXiv IDs found: 282\n",
      "Depth: 1, Unique ArXiv IDs found: 312\n",
      "Depth: 1, Unique ArXiv IDs found: 315\n",
      "Depth: 1, Unique ArXiv IDs found: 332\n",
      "Depth: 1, Unique ArXiv IDs found: 418\n",
      "Depth: 1, Unique ArXiv IDs found: 418\n",
      "Depth: 1, Unique ArXiv IDs found: 420\n",
      "Depth: 1, Unique ArXiv IDs found: 424\n",
      "Depth: 1, Unique ArXiv IDs found: 425\n",
      "Depth: 1, Unique ArXiv IDs found: 428\n",
      "Depth: 1, Unique ArXiv IDs found: 428\n",
      "Depth: 1, Unique ArXiv IDs found: 430\n",
      "Depth: 1, Unique ArXiv IDs found: 457\n",
      "Depth: 1, Unique ArXiv IDs found: 457\n",
      "Depth: 1, Unique ArXiv IDs found: 458\n",
      "Depth: 1, Unique ArXiv IDs found: 458\n",
      "Depth: 1, Unique ArXiv IDs found: 487\n",
      "Depth: 1, Unique ArXiv IDs found: 494\n",
      "Depth: 1, Unique ArXiv IDs found: 495\n",
      "Depth: 1, Unique ArXiv IDs found: 498\n",
      "Depth: 1, Unique ArXiv IDs found: 498\n",
      "Depth: 1, Unique ArXiv IDs found: 498\n",
      "Depth: 1, Unique ArXiv IDs found: 499\n",
      "Depth: 1, Unique ArXiv IDs found: 499\n",
      "Depth: 1, Unique ArXiv IDs found: 504\n",
      "Depth: 1, Unique ArXiv IDs found: 504\n",
      "Depth: 1, Unique ArXiv IDs found: 505\n",
      "Depth: 1, Unique ArXiv IDs found: 507\n",
      "Depth: 1, Unique ArXiv IDs found: 507\n",
      "Depth: 1, Unique ArXiv IDs found: 510\n",
      "Depth: 1, Unique ArXiv IDs found: 510\n",
      "Depth: 1, Unique ArXiv IDs found: 513\n",
      "Depth: 1, Unique ArXiv IDs found: 515\n",
      "Depth: 1, Unique ArXiv IDs found: 655\n",
      "Depth: 1, Unique ArXiv IDs found: 660\n",
      "Depth: 1, Unique ArXiv IDs found: 673\n",
      "Depth: 1, Unique ArXiv IDs found: 673\n",
      "Depth: 1, Unique ArXiv IDs found: 679\n",
      "Depth: 1, Unique ArXiv IDs found: 681\n",
      "Depth: 1, Unique ArXiv IDs found: 694\n",
      "Depth: 1, Unique ArXiv IDs found: 699\n",
      "Depth: 1, Unique ArXiv IDs found: 699\n",
      "Depth: 1, Unique ArXiv IDs found: 786\n",
      "Depth: 1, Unique ArXiv IDs found: 807\n",
      "Depth: 1, Unique ArXiv IDs found: 808\n",
      "Depth: 1, Unique ArXiv IDs found: 840\n",
      "Depth: 1, Unique ArXiv IDs found: 1002\n",
      "Depth: 1, Unique ArXiv IDs found: 1008\n",
      "Depth: 1, Unique ArXiv IDs found: 1014\n",
      "Depth: 1, Unique ArXiv IDs found: 1014\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 1, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1015\n",
      "Depth: 2, Unique ArXiv IDs found: 1016\n",
      "Depth: 2, Unique ArXiv IDs found: 1017\n",
      "Depth: 2, Unique ArXiv IDs found: 1017\n",
      "Depth: 2, Unique ArXiv IDs found: 1017\n",
      "Depth: 2, Unique ArXiv IDs found: 1017\n",
      "Depth: 2, Unique ArXiv IDs found: 1018\n",
      "Depth: 2, Unique ArXiv IDs found: 1018\n",
      "Depth: 2, Unique ArXiv IDs found: 1018\n",
      "Depth: 2, Unique ArXiv IDs found: 1018\n",
      "Depth: 2, Unique ArXiv IDs found: 1020\n",
      "Depth: 2, Unique ArXiv IDs found: 1020\n",
      "Depth: 2, Unique ArXiv IDs found: 1020\n",
      "Depth: 2, Unique ArXiv IDs found: 1020\n",
      "Depth: 2, Unique ArXiv IDs found: 1021\n",
      "Depth: 2, Unique ArXiv IDs found: 1026\n",
      "Depth: 2, Unique ArXiv IDs found: 1026\n",
      "Depth: 2, Unique ArXiv IDs found: 1026\n",
      "Depth: 2, Unique ArXiv IDs found: 1028\n",
      "Depth: 2, Unique ArXiv IDs found: 1030\n",
      "Depth: 2, Unique ArXiv IDs found: 1030\n",
      "Depth: 2, Unique ArXiv IDs found: 1035\n",
      "\n",
      "Process interrupted. Progress saved.\n",
      "\n",
      "Збереження інформації про 1491 пейперів.\n",
      "Дані збережено у файл 'data/arxiv_ids.csv'. Прогрес збережено.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "from collections import deque\n",
    "import csv\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class Paper:\n",
    "    arxiv_id: Optional[str]\n",
    "    authors: List[dict]\n",
    "    doi: Optional[str]\n",
    "    intent: List[str]\n",
    "    is_influential: bool\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    url: Optional[str]\n",
    "    venue: Optional[str]\n",
    "    year: Optional[int]\n",
    "\n",
    "def get_citations_from_semantic_scholar(paper_id: str) -> List[Paper]:\n",
    "    url = f\"https://api.semanticscholar.org/v1/paper/{paper_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        citations_data = data.get(\"citations\", [])\n",
    "        citations = [\n",
    "            Paper(\n",
    "                arxiv_id=citation.get('arxivId'),\n",
    "                authors=citation.get('authors', []),\n",
    "                doi=citation.get('doi'),\n",
    "                intent=citation.get('intent', []),\n",
    "                is_influential=citation.get('isInfluential', False),\n",
    "                paper_id=citation['paperId'],\n",
    "                title=citation.get('title', ''),\n",
    "                url=citation.get('url'),\n",
    "                venue=citation.get('venue', ''),\n",
    "                year=citation.get('year')\n",
    "            ) for citation in citations_data\n",
    "        ]\n",
    "        return citations\n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limit exceeded for Paper ID: {paper_id}. Exiting.\")\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} for Paper ID: {paper_id}\")\n",
    "        return []\n",
    "\n",
    "def save_queue(queue, filename=\"data/queue.txt\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for paper_id, depth in queue:\n",
    "            file.write(f\"{paper_id},{depth}\\n\")\n",
    "\n",
    "def load_queue(filename=\"data/queue.txt\"):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            queue = deque()\n",
    "            for line in file:\n",
    "                paper_id, depth = line.strip().split(',')\n",
    "                queue.append((paper_id, int(depth)))\n",
    "            return queue\n",
    "    return deque()\n",
    "\n",
    "def save_visited(visited_papers, arxiv_ids, filename=\"data/visited.txt\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for paper_id in visited_papers:\n",
    "            file.write(f\"{paper_id}\\n\")\n",
    "        file.write(\"---\\n\")\n",
    "        for arxiv_id in arxiv_ids:\n",
    "            file.write(f\"{arxiv_id}\\n\")\n",
    "\n",
    "def load_visited(filename=\"data/visited.txt\"):\n",
    "    visited_papers = set()\n",
    "    arxiv_ids = set()\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            separator = lines.index('---\\n')  # Розділювач між visited_papers та arxiv_ids\n",
    "            visited_papers = set(line.strip() for line in lines[:separator])\n",
    "            arxiv_ids = set(line.strip() for line in lines[separator+1:])\n",
    "    return visited_papers, arxiv_ids\n",
    "\n",
    "def find_all_citations(paper_id: str, delay=0.1, queue_file=\"data/queue.txt\", visited_file=\"data/visited.txt\"):\n",
    "    papers = []\n",
    "\n",
    "    # Завантажуємо чергу, відвідані документи та знайдені ArXiv IDs\n",
    "    queue = load_queue(queue_file)\n",
    "    visited_papers, arxiv_ids = load_visited(visited_file)\n",
    "\n",
    "    if not queue:\n",
    "        queue.append((paper_id, 0))\n",
    "\n",
    "    try:\n",
    "        while queue:\n",
    "            current_paper_id, depth = queue.popleft()\n",
    "            if current_paper_id in visited_papers:\n",
    "                continue\n",
    "            visited_papers.add(current_paper_id)\n",
    "            citations = get_citations_from_semantic_scholar(current_paper_id)\n",
    "            if citations is None:\n",
    "                break\n",
    "            print(f\"Depth: {depth}, Unique ArXiv IDs found: {len(arxiv_ids)}\")\n",
    "            for citation in citations:\n",
    "                citation_id = citation.paper_id\n",
    "                if citation.arxiv_id:\n",
    "                    arxiv_ids.add(citation.arxiv_id)\n",
    "                papers.append(citation)\n",
    "                if citation_id not in visited_papers:\n",
    "                    queue.append((citation_id, depth + 1))\n",
    "            time.sleep(delay)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted. Progress saved.\")\n",
    "        save_queue(queue, queue_file)\n",
    "        save_visited(visited_papers, arxiv_ids, visited_file)\n",
    "        return papers\n",
    "\n",
    "    # Зберігаємо прогрес після завершення\n",
    "    save_queue(queue, queue_file)\n",
    "    save_visited(visited_papers, arxiv_ids, visited_file)\n",
    "    return papers\n",
    "\n",
    "def save_papers_to_csv(papers: List[Paper], filename=\"data/arxiv_ids.csv\"):\n",
    "    if not os.path.exists(filename):\n",
    "        # Якщо файл не існує, створюємо його з заголовками\n",
    "        with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"arxiv_id\", \"authors\", \"doi\", \"intent\", \"is_influential\", \"paper_id\", \"title\", \"url\", \"venue\", \"year\"])\n",
    "    with open(filename, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for paper in papers:\n",
    "            authors = \", \".join([author['name'] for author in paper.authors])\n",
    "            writer.writerow([paper.arxiv_id, authors, paper.doi, \"; \".join(paper.intent), paper.is_influential, paper.paper_id, paper.title, paper.url, paper.venue, paper.year])\n",
    "\n",
    "def load_existing_papers(filename=\"data/arxiv_ids.csv\"):\n",
    "    existing_papers = set()\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, mode=\"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Пропускаємо заголовок\n",
    "            for row in reader:\n",
    "                existing_papers.add(row[5])  # Додаємо paper_id до існуючих\n",
    "    return existing_papers\n",
    "\n",
    "main_paper_id = \"87875a07976c26f82705de1fc70041169e5d652b\"\n",
    "existing_papers = load_existing_papers(\"data/arxiv_ids.csv\")\n",
    "papers = find_all_citations(main_paper_id, delay=0.1)\n",
    "\n",
    "print(f\"\\nЗбереження інформації про {len(papers)} пейперів.\")\n",
    "save_papers_to_csv(papers, \"data/arxiv_ids.csv\")\n",
    "print(\"Дані збережено у файл 'data/arxiv_ids.csv'. Прогрес збережено.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Завантаження і обробка пейперів:   2%| | 21/1400 [03:07<3:24:41,  8.91s/пейпер, Залишилось=1379 пейп\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mВсі файли архівовані в: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Виклик функції для завантаження та архівації пейперів\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m download_and_extract_all_papers(arxiv_ids_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/arxiv_ids.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/arxiv_papers\u001b[39m\u001b[38;5;124m\"\u001b[39m, zip_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/papers_archive.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 75\u001b[0m, in \u001b[0;36mdownload_and_extract_all_papers\u001b[1;34m(arxiv_ids_file, save_dir, zip_filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m download_paper(arxiv_id, save_dir)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pdf_path:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Витягуємо текст з PDF\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_path)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;66;03m# Створюємо текстовий файл і додаємо його до архіву\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         text_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marxiv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages:\n\u001b[1;32m---> 29\u001b[0m             text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:538\u001b[0m, in \u001b[0;36mPage.extract_text\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_textmap(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtuplify_list_kwargs(kwargs))\u001b[38;5;241m.\u001b[39mas_string\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:515\u001b[0m, in \u001b[0;36mPage._get_textmap\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     defaults\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_height\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight})\n\u001b[0;32m    514\u001b[0m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefaults, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mchars_to_textmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[0m, in \u001b[0;36mContainer.chars\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_obj_list:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:347\u001b[0m, in \u001b[0;36mPage.objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_objects()\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:451\u001b[0m, in \u001b[0;36mPage.parse_objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[0;32m    450\u001b[0m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_layout_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39m_objs):\n\u001b[0;32m    452\u001b[0m         kind \u001b[38;5;241m=\u001b[39m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manno\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:277\u001b[0m, in \u001b[0;36mPage.layout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m device \u001b[38;5;241m=\u001b[39m PDFPageAggregatorWithMarkedContent(\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr,\n\u001b[0;32m    273\u001b[0m     pageno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_number,\n\u001b[0;32m    274\u001b[0m     laparams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mlaparams,\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    276\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr, device)\n\u001b[1;32m--> 277\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mprocess_page(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_obj)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout: LTPage \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mget_result()\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:997\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    995\u001b[0m     ctm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mx0, \u001b[38;5;241m-\u001b[39my0)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_page(page, ctm)\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_contents(page\u001b[38;5;241m.\u001b[39mresources, page\u001b[38;5;241m.\u001b[39mcontents, ctm\u001b[38;5;241m=\u001b[39mctm)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_page(page)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(list_value(streams))\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1042\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name, args)\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m nargs:\n\u001b[1;32m-> 1042\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:972\u001b[0m, in \u001b[0;36mPDFPageInterpreter.do_Do\u001b[1;34m(self, xobjid_arg)\u001b[0m\n\u001b[0;32m    970\u001b[0m         resources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_figure(xobjid, bbox, matrix)\n\u001b[1;32m--> 972\u001b[0m     interpreter\u001b[38;5;241m.\u001b[39mrender_contents(\n\u001b[0;32m    973\u001b[0m         resources, [xobj], ctm\u001b[38;5;241m=\u001b[39mmult_matrix(matrix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctm)\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_figure(xobjid)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m subtype \u001b[38;5;129;01mis\u001b[39;00m LITERAL_IMAGE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWidth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m xobj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m xobj:\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(list_value(streams))\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1027\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1027\u001b[0m         (_, obj) \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mnextobject()\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[0;32m   1029\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\psparser.py:609\u001b[0m, in \u001b[0;36mPSStackParser.nextobject\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields a list of objects.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03mArrays and dictionaries are represented as Python lists and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m:return: keywords, literals, strings, numbers, arrays and dictionaries.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m--> 609\u001b[0m     (pos, token) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnexttoken()\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, PSLiteral)):\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;66;03m# normal token\u001b[39;00m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush((pos, token))\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\pdfminer\\psparser.py:529\u001b[0m, in \u001b[0;36mPSBaseParser.nexttoken\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharpos)\n\u001b[0;32m    528\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokens\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 529\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnexttoken: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\logging\\__init__.py:1517\u001b[0m, in \u001b[0;36mLogger.debug\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m _checkLevel(level)\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39m_clear_cache()\n\u001b[1;32m-> 1517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;124;03m    Log 'msg % args' with severity 'DEBUG'.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;124;03m    logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=True)\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(DEBUG):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import time\n",
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "def download_paper(arxiv_id, save_dir=\"data/arxiv_papers\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(save_dir, f\"{arxiv_id}.pdf\")\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return file_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Помилка при обробці PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def add_to_zip(zip_file, file_path):\n",
    "    zip_file.write(file_path, os.path.basename(file_path))\n",
    "\n",
    "def load_processed_ids(filename=\"data/processed_ids.txt\"):\n",
    "    \"\"\"Завантажуємо список вже оброблених арXiv ID.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return set(line.strip() for line in f)\n",
    "    return set()\n",
    "\n",
    "def save_processed_id(arxiv_id, filename=\"data/processed_ids.txt\"):\n",
    "    \"\"\"Зберігаємо оброблений арXiv ID у файл.\"\"\"\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"{arxiv_id}\\n\")\n",
    "\n",
    "def download_and_extract_all_papers(arxiv_ids_file=\"data/arxiv_ids.csv\", save_dir=\"data/arxiv_papers\", zip_filename=\"data/papers_archive.zip\"):\n",
    "    arxiv_ids = []\n",
    "    # Читаємо арXiv IDs з CSV файлу\n",
    "    with open(arxiv_ids_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            arxiv_id = row['arxiv_id']\n",
    "            if arxiv_id:\n",
    "                arxiv_ids.append(arxiv_id)\n",
    "\n",
    "    total_papers = len(arxiv_ids)\n",
    "    processed_ids = load_processed_ids(\"data/processed_ids.txt\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, 'a', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "        with tqdm(total=total_papers, desc=\"Завантаження і обробка пейперів\", unit=\"пейпер\", ncols=100) as pbar:\n",
    "            start_time = time.time()\n",
    "            for i, arxiv_id in enumerate(arxiv_ids, 1):\n",
    "                if arxiv_id in processed_ids:\n",
    "                    # Пропускаємо вже оброблені пейпери\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                pdf_path = download_paper(arxiv_id, save_dir)\n",
    "                if pdf_path:\n",
    "                    # Витягуємо текст з PDF\n",
    "                    text = extract_text_from_pdf(pdf_path)\n",
    "                    if text:\n",
    "                        # Створюємо текстовий файл і додаємо його до архіву\n",
    "                        text_filename = os.path.join(save_dir, f\"{arxiv_id}.txt\")\n",
    "                        with open(text_filename, 'w', encoding='utf-8') as text_file:\n",
    "                            text_file.write(text)\n",
    "                        add_to_zip(zip_file, text_filename)\n",
    "\n",
    "                    # Зберігаємо оброблений ID\n",
    "                    save_processed_id(arxiv_id, \"data/processed_ids.txt\")\n",
    "\n",
    "                    pbar.set_postfix({'Залишилось': f\"{total_papers - i} пейперів\"})\n",
    "                else:\n",
    "                    pbar.set_postfix({'Залишилось': f\"{total_papers - i} пейперів\", 'Статус': 'Помилка'})\n",
    "                pbar.update(1)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_time_remaining = elapsed_time / i * (total_papers - i) if i > 0 else 0\n",
    "            print(f\"Час виконання: {elapsed_time:.2f} сек. Оцінка часу до завершення: {estimated_time_remaining:.2f} сек.\")\n",
    "\n",
    "    print(f\"Всі файли архівовані в: {zip_filename}\")\n",
    "\n",
    "# Виклик функції для завантаження та архівації пейперів\n",
    "download_and_extract_all_papers(arxiv_ids_file=\"data/arxiv_ids.csv\", save_dir=\"data/arxiv_papers\", zip_filename=\"data/papers_archive.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('local_model\\\\tokenizer_config.json',\n",
       " 'local_model\\\\special_tokens_map.json',\n",
       " 'local_model\\\\vocab.json',\n",
       " 'local_model\\\\merges.txt',\n",
       " 'local_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(\"local_model\")\n",
    "tokenizer.save_pretrained(\"local_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9509e4f5e92841ce924e6fe809be50cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка файлів:   0%|          | 1/631 [1:53:15<1189:12:41, 6795.49s/файл]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     31\u001b[0m     text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 32\u001b[0m     summary \u001b[38;5;241m=\u001b[39m summarize_text(text)\n\u001b[0;32m     33\u001b[0m     summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n\u001b[0;32m     34\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m, in \u001b[0;36msummarize_text\u001b[1;34m(text, max_length)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_text\u001b[39m(text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m     19\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39mmax_length)\n\u001b[0;32m     21\u001b[0m     summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2245\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2246\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2247\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2249\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2253\u001b[0m         input_ids,\n\u001b[0;32m   2254\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2255\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2256\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2257\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2258\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2259\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2260\u001b[0m     )\n\u001b[0;32m   2262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2265\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2266\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2272\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3254\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3252\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3254\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3256\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3257\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3258\u001b[0m     outputs,\n\u001b[0;32m   3259\u001b[0m     model_kwargs,\n\u001b[0;32m   3260\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3261\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:968\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    966\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 968\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    969\u001b[0m     input_ids,\n\u001b[0;32m    970\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    971\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    972\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    973\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    974\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    975\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    976\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    977\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    978\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    979\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    980\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    981\u001b[0m )\n\u001b[0;32m    982\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    984\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:750\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    739\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    740\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    741\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m         cache_position,\n\u001b[0;32m    748\u001b[0m     )\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 750\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m    751\u001b[0m         hidden_states,\n\u001b[0;32m    752\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    753\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    754\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m    755\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    756\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    757\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    758\u001b[0m     )\n\u001b[0;32m    760\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:475\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    473\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    474\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 475\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m    477\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:432\u001b[0m, in \u001b[0;36mGPTNeoMLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    430\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m    431\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m--> 432\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[0;32m    433\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\arsen\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"local_model\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"local_model\")\n",
    "\n",
    "zip_file_path = \"papers_archive.zip\"\n",
    "extracted_files_dir = \"extracted_papers\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_files_dir)\n",
    "def summarize_text(text, max_length=200):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_length)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "file_list = [f for f in os.listdir(extracted_files_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "summaries = []\n",
    "with tqdm(total=len(file_list), desc=\"Обробка файлів\", unit=\"файл\") as pbar:\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(extracted_files_dir, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            summary = summarize_text(text)\n",
    "            summaries.append(summary)\n",
    "        pbar.update(1)\n",
    "\n",
    "full_summary = \" \".join(summaries)\n",
    "final_summary = summarize_text(full_summary)\n",
    "\n",
    "print(\"Фінальний висновок про статті:\")\n",
    "print(final_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка файлів:   5%|▍         | 31/631 [1:55:27<36:24:35, 218.46s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Шлях до архіву\n",
    "zip_file_path = \"papers_archive.zip\"\n",
    "\n",
    "# Завантаження моделі та токенайзера на GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Функція для обробки одного файлу\n",
    "def process_file(file_name, content):\n",
    "    input_text = content.decode(\"utf-8\")[:1000]  # Візьмемо лише перші 1000 символів для прикладу\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150, pad_token_id=tokenizer.eos_token_id)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Розпакування архіву та обробка файлів\n",
    "def process_files_from_zip(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        for file_name in tqdm(file_list, desc=\"Обробка файлів\"):\n",
    "            if file_name.endswith('.txt'):\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    content = file.read()\n",
    "                    summary = process_file(file_name, content)\n",
    "                    save_summary(file_name, summary)\n",
    "\n",
    "# Функція для збереження результатів\n",
    "def save_summary(file_name, summary):\n",
    "    with open(f\"summary_{file_name.replace('/', '_')}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(summary)\n",
    "\n",
    "# Виклик функції обробки файлів\n",
    "process_files_from_zip(zip_file_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
